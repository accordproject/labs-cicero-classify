{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:48:39.607943Z",
     "start_time": "2021-08-19T01:48:39.570780Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:48:39.882005Z",
     "start_time": "2021-08-19T01:48:39.609421Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:48:39.891232Z",
     "start_time": "2021-08-19T01:48:39.883434Z"
    }
   },
   "outputs": [],
   "source": [
    "from core.config import MONGODB_URL, DATABASE_NAME, Feedback_Label_Collection, LABEL_COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T02:16:59.625568Z",
     "start_time": "2021-08-19T02:16:59.620199Z"
    }
   },
   "outputs": [],
   "source": [
    "col = client[DATABASE_NAME][Feedback_Label_Collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T02:17:03.219617Z",
     "start_time": "2021-08-19T02:17:03.208038Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eason/anaconda3/envs/adapter/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47960"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.364349Z",
     "start_time": "2021-08-19T01:48:39.892791Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████▊                         | 9068/47959 [00:53<03:50, 168.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13455/2075132518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msentense_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sentence #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_and_labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msentense_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sentence #\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentense_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multiTags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/adapter/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8963\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8964\u001b[0m                 \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8965\u001b[0;31m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8966\u001b[0m             )\n\u001b[1;32m   8967\u001b[0m         ).__finalize__(self, method=\"append\")\n",
      "\u001b[0;32m~/anaconda3/envs/adapter/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/adapter/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/adapter/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             new_data = concatenate_managers(\n\u001b[0;32m--> 533\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m             )\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/adapter/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0;31m#  we can use np.concatenate, which is more performant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;31m#  than concat_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient(MONGODB_URL)\n",
    "\n",
    "col = client[DATABASE_NAME][Feedback_Label_Collection]\n",
    "\n",
    "result = col.find({\"user\": \"CONLL_0818@admin\"})\n",
    "\n",
    "result = list(result)\n",
    "\n",
    "from tqdm import tqdm\n",
    "df = pd.DataFrame()\n",
    "for i, sentence in enumerate(tqdm(result)):\n",
    "    sentense_df = pd.DataFrame(columns=[\"Sentence #\", \"text\", \"labels\"], data = sentence[\"text_and_labels\"])\n",
    "    sentense_df[\"Sentence #\"] = str(sentence[\"_id\"])\n",
    "    df = df.append(sentense_df)\n",
    "\n",
    "df[\"multiTags\"] = df.labels.apply(lambda x: \"|\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T00:59:46.489464Z",
     "start_time": "2021-08-18T00:59:46.487145Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.365678Z",
     "start_time": "2021-08-19T01:49:38.365668Z"
    }
   },
   "outputs": [],
   "source": [
    "result = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:23:21.283649Z",
     "start_time": "2021-08-18T00:59:50.868602Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.366801Z",
     "start_time": "2021-08-19T01:49:38.366791Z"
    }
   },
   "outputs": [],
   "source": [
    "label_name = \"Party87\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.367874Z",
     "start_time": "2021-08-19T01:49:38.367863Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_search_filter = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.368626Z",
     "start_time": "2021-08-19T01:49:38.368615Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_training_dataframe(train_data_search_filter = {}):\n",
    "\n",
    "    col = client[DATABASE_NAME][Feedback_Label_Collection]\n",
    "\n",
    "    result = col.find(train_data_search_filter)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i, sentence in enumerate(tqdm(result)):\n",
    "        sentense_df = pd.DataFrame(columns=[\"Sentence #\", \"text\", \"labels\"], data = sentence[\"text_and_labels\"])\n",
    "        sentense_df[\"Sentence #\"] = str(sentence[\"_id\"])\n",
    "        df = df.append(sentense_df)\n",
    "    return df\n",
    "def get_training_data_by_df_according_to_label_name(df, label_name):\n",
    "    label_col = client[DATABASE_NAME][LABEL_COLLECTION]\n",
    "\n",
    "    label_info = label_col.find_one({\"label_name\": label_name})\n",
    "    alias_labels = label_col.find({\"alias_as\": {\"$in\": [label_name]}})\n",
    "\n",
    "    alias = []\n",
    "    for alias_label in alias_labels:\n",
    "        alias.append(alias_label[\"label_name\"])\n",
    "    alias = alias + label_info[\"inherit\"]\n",
    "\n",
    "    wanted_label = [label_name] + alias\n",
    "\n",
    "    def label_data(label):\n",
    "        if set(label).intersection(set(wanted_label)):\n",
    "            return label_name\n",
    "        else:\n",
    "            return \"O\"\n",
    "\n",
    "    df[label_name] = list(df[\"labels\"].apply(label_data))\n",
    "\n",
    "    sentences = df.groupby(\"Sentence #\")[\"text\"].apply(list).values\n",
    "    tags = df.groupby(\"Sentence #\")[label_name].apply(list).values\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.369641Z",
     "start_time": "2021-08-19T01:49:38.369629Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.370714Z",
     "start_time": "2021-08-19T01:49:38.370703Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.371535Z",
     "start_time": "2021-08-19T01:49:38.371521Z"
    }
   },
   "outputs": [],
   "source": [
    "self = classmethod(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.372584Z",
     "start_time": "2021-08-19T01:49:38.372574Z"
    }
   },
   "outputs": [],
   "source": [
    "class NER_Dataset_for_Adapter(Dataset):\n",
    "    def __init__(self, tokenizer, df, label_name):\n",
    "        self.label_name = label_name\n",
    "        self.mode = \"train\"\n",
    "        # 大數據你會需要用 iterator=True\n",
    "        self.sentences, self.tags = get_training_data_by_df_according_to_label_name(df, label_name)\n",
    "        self.len = len(self.sentences)\n",
    "\n",
    "\n",
    "        labels = [\"O\", label_name]\n",
    "\n",
    "        if self.mode != \"test\":\n",
    "            labels = [\"O\", label_name]\n",
    "            self.label_map = {}\n",
    "            for i, label in enumerate(labels):\n",
    "                self.label_map[label] = i\n",
    "\n",
    "            possible_labels = np.array(range(len(labels))).reshape(-1, 1)\n",
    "            self.oneHotEncoder = OneHotEncoder()\n",
    "            self.oneHotEncoder.fit(possible_labels)\n",
    "        else:\n",
    "            self.label_map = None\n",
    "\n",
    "        self.tokenizer = tokenizer  # RoBERTa tokenizer\n",
    "        self.O_label = self.label_map[\"O\"]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            label = [\"O\"] + self.tags[idx] + [\"O\"]\n",
    "\n",
    "            label = np.array(label)\n",
    "            label = label.reshape(-1,1)\n",
    "\n",
    "            label = np.apply_along_axis(self.split_one_hot_multiTags, 1, label)\n",
    "            label_tensor = torch.tensor(label, dtype = torch.float32)\n",
    "\n",
    "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "        word_pieces = [tokenizer.cls_token]\n",
    "        word_pieces += self.sentences[idx]\n",
    "        word_pieces += [tokenizer.sep_token]\n",
    "\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "\n",
    "        # 將第一句包含 [SEP] 的 token 位置設為 0\n",
    "        segments_tensor = torch.zeros_like(tokens_tensor)\n",
    "\n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def split_one_hot_multiTags(self, tags):\n",
    "        # tags = ['B-org|Party|String']\n",
    "        tags = tags[0]\n",
    "        tags = tags.split(\"|\")\n",
    "\n",
    "\n",
    "        tags_num = list(map(lambda x: self.label_map[x], tags))\n",
    "        #[5, 20, 23]\n",
    "\n",
    "        tags_num = np.array(tags_num).reshape(-1,1)\n",
    "\n",
    "        tags_one_hot = self.oneHotEncoder.transform(tags_num).toarray()\n",
    "\n",
    "        tags_one_hot = tags_one_hot.sum(axis = 0)\n",
    "\n",
    "        #return torch.tensor(tags_one_hot, dtype = torch.float32)\n",
    "\n",
    "        return tags_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.373429Z",
     "start_time": "2021-08-19T01:49:38.373419Z"
    }
   },
   "outputs": [],
   "source": [
    "NER_multilabel_data_v2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.374246Z",
     "start_time": "2021-08-19T01:49:38.374236Z"
    }
   },
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:30:54.724090Z",
     "start_time": "2021-08-19T01:30:54.721414Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.374890Z",
     "start_time": "2021-08-19T01:49:38.374880Z"
    }
   },
   "outputs": [],
   "source": [
    "self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T01:49:38.376062Z",
     "start_time": "2021-08-19T01:49:38.376051Z"
    }
   },
   "outputs": [],
   "source": [
    "wanted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
