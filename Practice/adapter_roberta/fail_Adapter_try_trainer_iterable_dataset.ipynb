{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c64f2ee6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-29T07:49:57.535Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced4b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beafcfe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:09.796665Z",
     "start_time": "2021-07-29T07:47:09.303517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.8.1\n",
      "transformers (Adapter) Version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"transformers (Adapter) Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aff5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add515cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:20.374877Z",
     "start_time": "2021-07-29T07:47:09.799877Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215447e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43bfdc87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:20.849169Z",
     "start_time": "2021-07-29T07:47:20.378077Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"./NER_multilabel_data_v2.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda448ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:20.923014Z",
     "start_time": "2021-07-29T07:47:20.852642Z"
    }
   },
   "outputs": [],
   "source": [
    "all_tags = df.newTag\n",
    "\n",
    "all_tags = set(all_tags)\n",
    "\n",
    "all_tags = \"|\".join(all_tags)\n",
    "all_tags = all_tags.split(\"|\")\n",
    "all_tags = set(all_tags)\n",
    "all_tags = list(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d39f8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:20.932530Z",
     "start_time": "2021-07-29T07:47:20.925368Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_csv(data_path):\n",
    "    df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    "    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
    "    tags = df.groupby(\"Sentence #\")[\"newTag\"].apply(list).values\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c2799ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:23.134798Z",
     "start_time": "2021-07-29T07:47:20.934012Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences, tags = process_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef80e76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:26.777242Z",
     "start_time": "2021-07-29T07:47:23.137854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['B-art' 'B-eve' 'B-geo' 'B-gpe' 'B-nat' 'B-org' 'B-per' 'B-tim'\n",
      " 'CountryCode' 'CryptoCurrencyCode' 'CurrencyCode' 'Event' 'Float' 'I-art'\n",
      " 'I-eve' 'I-geo' 'I-gpe' 'I-nat' 'I-org' 'I-per' 'I-tim' 'Integer'\n",
      " 'Location' 'Month' 'O' 'Object' 'Party' 'Race' 'SpecialTerm'\n",
      " 'TemporalUnit' 'Time' 'Timezone' 'US_States']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class NER_Dataset(Dataset):\n",
    "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
    "    def __init__(self, mode, tokenizer, data_path, labels):\n",
    "        assert mode in [\"train\", \"test\"]  # 一般訓練你會需要 dev set\n",
    "        self.mode = mode\n",
    "        # 大數據你會需要用 iterator=True\n",
    "        self.sentences, self.tags = process_csv(data_path)\n",
    "        self.len = len(self.sentences)\n",
    "        \n",
    "\n",
    "        if mode != \"test\":\n",
    "            self.label_map = {}\n",
    "            for i in range(len(labels)):\n",
    "                self.label_map[labels[i]] = i\n",
    "                \n",
    "            possible_labels = np.array(range(len(labels))).reshape(-1, 1)\n",
    "            self.oneHotEncoder = OneHotEncoder()\n",
    "            self.oneHotEncoder.fit(possible_labels)\n",
    "        else:\n",
    "            self.label_map = None\n",
    "        \n",
    "        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n",
    "        self.O_label = self.label_map[\"O\"]\n",
    "\n",
    "    \n",
    "    # 定義回傳一筆訓練 / 測試數據的函式\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            label = [\"O\"] + self.tags[idx] + [\"O\"]\n",
    "\n",
    "            label = np.array(label)\n",
    "            label = label.reshape(-1,1)\n",
    "\n",
    "            label = np.apply_along_axis(self.split_one_hot_multiTags, 1, label)\n",
    "            label_tensor = torch.tensor(label, dtype = torch.float32)\n",
    "            \n",
    "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "        word_pieces = ['[CLS]']\n",
    "        word_pieces += self.sentences[idx]\n",
    "        word_pieces += ['[SEP]']\n",
    "        \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # 將第一句包含 [SEP] 的 token 位置設為 0\n",
    "        segments_tensor = torch.zeros_like(tokens_tensor)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def split_one_hot_multiTags(self, tags):\n",
    "        # tags = ['B-org|Party|String']\n",
    "        tags = tags[0]\n",
    "        tags = tags.split(\"|\")\n",
    "\n",
    "\n",
    "        tags_num = list(map(lambda x: self.label_map[x], tags))\n",
    "        #[5, 20, 23]\n",
    "\n",
    "        tags_num = np.array(tags_num).reshape(-1,1)\n",
    "\n",
    "        tags_one_hot = self.oneHotEncoder.transform(tags_num).toarray()\n",
    "\n",
    "        tags_one_hot = tags_one_hot.sum(axis = 0)\n",
    "\n",
    "        #return torch.tensor(tags_one_hot, dtype = torch.float32)\n",
    "\n",
    "        return tags_one_hot\n",
    "    \n",
    "    \n",
    "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "\n",
    "labels = np.unique(\"|\".join(list(df.newTag)).split(\"|\"))\n",
    "print(f\"labels: {labels}\")\n",
    "\n",
    "trainset = NER_Dataset(\"train\", tokenizer=tokenizer, data_path=data_path, labels= labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "264f724a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:26.785973Z",
     "start_time": "2021-07-29T07:47:26.779803Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # 測試集有 labels\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = [s[2] for s in samples]\n",
    "        label_ids = pad_sequence(label_ids, \n",
    "                                  batch_first=True)\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40d3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d586897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383271a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16c29d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:31.543141Z",
     "start_time": "2021-07-29T07:47:26.787728Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModelWithHeads\n",
    "\n",
    "config = RobertaConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=2,\n",
    ")\n",
    "model = RobertaModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99812659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.146041Z",
     "start_time": "2021-07-29T07:47:31.548139Z"
    }
   },
   "outputs": [],
   "source": [
    "for tag in all_tags:\n",
    "    break\n",
    "    model.add_adapter(tag)\n",
    "    model.add_tagging_head(\n",
    "        tag,\n",
    "        num_labels=2\n",
    "      )\n",
    "    model.train_adapter(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31110f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"ALL\"\n",
    "model.add_adapter(tag)\n",
    "model.add_tagging_head(\n",
    "    tag,\n",
    "    num_labels=len(trainset.label_map.keys())\n",
    "  )\n",
    "model.train_adapter(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80ee7086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALL'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252730e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2c3f5b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.211287Z",
     "start_time": "2021-07-29T07:47:32.208313Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e81629db",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'inp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1772/1090311061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_ndx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'inp'"
     ]
    }
   ],
   "source": [
    "for batch_ndx, sample in enumerate(trainloader):\n",
    "    print(sample.inp.is_pinned())\n",
    "    print(sample.tgt.is_pinned())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ef36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f04a7442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.245131Z",
     "start_time": "2021-07-29T07:47:32.212463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(f\"\"\"\\ntokens_tensors.shape   = {tokens_tensors.shape} \\n{tokens_tensors}\\n------------------------\\nsegments_tensors.shape = {segments_tensors.shape}\\n{segments_tensors}\\n------------------------\\nmasks_tensors.shape    = {masks_tensors.shape}\\n{masks_tensors}\\n------------------------\\nlabel_ids.shape        = {label_ids.shape}\\n{label_ids}\\n\"\"\")'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "\n",
    "tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = data\n",
    "\n",
    "'''print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "------------------------\n",
    "segments_tensors.shape = {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------\n",
    "masks_tensors.shape    = {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "------------------------\n",
    "label_ids.shape        = {label_ids.shape}\n",
    "{label_ids}\n",
    "\"\"\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bc001dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:35.059990Z",
     "start_time": "2021-07-29T07:47:32.246954Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a1b06071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.IterableDataset at 0x7fc9358cb490>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.IterableDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "050b3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, loader = trainloader, filter_tag = \"O\"):\n",
    "        super(MyIterableDataset).__init__()\n",
    "        self.loader = loader\n",
    "        self.filter_tag = filter_tag\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        return (iter(self.loader))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "    \n",
    "    def __dict__(self):\n",
    "        return vars(self.loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0cee445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyIterableDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ceb3eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=200,\n",
    "    output_dir=\"./training_output\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"acc\": (preds == p.label_ids).mean()}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a9512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade06e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f656694b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "vars() argument must have __dict__ attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1772/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mdefault_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# on the whole batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# on the whole batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c6658c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c5dc066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/home/eason/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/e06abb624abab47e1a64608fdfe65a913f5a68c66118408032644a3285208fb5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 8530, 'validation': 1066, 'test': 1066}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d4f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd4b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38e5311e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:48:25.782940Z",
     "start_time": "2021-07-29T07:47:35.063129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 3 µs, total: 16 µs\n",
      "Wall time: 28.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CPU times: user 4min 19s, sys: 212 ms, total: 4min 19s\\nWall time: 4min 19s'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"times = 0\n",
    "for data in trainloader:\n",
    "    times += 1\"\"\"\n",
    "\n",
    "\"\"\"CPU times: user 4min 19s, sys: 212 ms, total: 4min 19s\n",
    "Wall time: 4min 19s\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf86df7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:48:25.785423Z",
     "start_time": "2021-07-29T07:48:25.785411Z"
    }
   },
   "outputs": [],
   "source": [
    "times = 11990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851879b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da175050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_count:\n",
    "    def __init__(self):\n",
    "        self.all_loss = 0\n",
    "        self.times = 0\n",
    "    def add(self, i):\n",
    "        self.all_loss += i\n",
    "        self.times += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "159f34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, data, device, optimizer, loss_count):\n",
    "    tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = [t.to(device) for t in data]\n",
    "\n",
    "    out = model(input_ids = tokens_tensors, attention_mask = masks_tensors, segments_tensors = segments_tensors)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(len(all_tags)):\n",
    "        adapter_name = all_tags[i]\n",
    "        tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "        current_tag = label_ids[:,:, tag_index]\n",
    "\n",
    "\n",
    "        out[i][0].shape\n",
    "\n",
    "        actual = torch.zeros(out[i][0].shape, device = device)\n",
    "\n",
    "        actual[:,:,1] = current_tag\n",
    "        actual[:,:,0] = (current_tag == 0).float()\n",
    "\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        loss = loss_fct(out[i][0], actual)\n",
    "        loss_count.add(loss)\n",
    "        if i <= len(all_tags) -1:\n",
    "            loss.backward(retain_graph=True)\n",
    "        else:\n",
    "            loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    del tokens_tensors, segments_tensors, masks_tensors, label_ids, loss, actual, current_tag\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b41aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d213fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b779d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3548675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d1ef698",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1644/1880721193.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "        # \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        out = torch.zeros((tokens_tensors.shape[0], tokens_tensors.shape[1]), device = device).long()\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                        token_type_ids=segments_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=out)\n",
    "\n",
    "        loss = outputs[0][0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # add to batch loss\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac86eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9daffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b92421",
   "metadata": {},
   "source": [
    "# 目前看來外部再算 Loss 的方法行不通，記憶體會炸掉，因此改為試試看，在 Label 的部分做文章，然後選擇性地去 Loss 試試看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35547c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(trainloader))\n",
    "tokens_tensors, segments_tensors, \\\n",
    "masks_tensors, label_ids = [t.to(device) for t in data]\n",
    "\n",
    "out = model(input_ids = tokens_tensors, attention_mask = masks_tensors, segments_tensors = segments_tensors)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "for i in range(len(all_tags)):\n",
    "    adapter_name = all_tags[i]\n",
    "    tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "    current_tag = label_ids[:,:, tag_index]\n",
    "\n",
    "\n",
    "    out[i][0].shape\n",
    "\n",
    "    actual = torch.zeros(out[i][0].shape, device = device)\n",
    "\n",
    "    actual[:,:,1] = current_tag\n",
    "    actual[:,:,0] = (current_tag == 0).float()\n",
    "\n",
    "    loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss = loss_fct(out[i][0], actual)\n",
    "\n",
    "    loss.backward(retain_graph=True)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "848e1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_label = torch.zeros(tokens_tensors.shape, device = device).long()\n",
    "out = model(input_ids = tokens_tensors,\n",
    "            attention_mask = masks_tensors,\n",
    "            segments_tensors = segments_tensors,\n",
    "            labels = tmp_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66640d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a67d8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_name = all_tags[i]\n",
    "tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "current_tag = label_ids[:,:, tag_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f514ad90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bddd61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f431573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=tensor(2.1799e-05, device='cuda:1', grad_fn=<NllLossBackward>), logits=tensor([[[ 5.3136, -4.6688],\n",
       "         [ 6.2403, -5.2024],\n",
       "         [ 5.9424, -5.2621],\n",
       "         [ 5.9892, -5.3082],\n",
       "         [ 5.8272, -5.3263],\n",
       "         [ 6.0709, -5.7180],\n",
       "         [ 5.7603, -4.9385],\n",
       "         [ 6.1404, -5.1860],\n",
       "         [ 5.9128, -5.0043],\n",
       "         [ 6.0323, -5.4904],\n",
       "         [ 6.1061, -5.1775],\n",
       "         [ 5.8515, -5.1434],\n",
       "         [ 5.5018, -4.7776],\n",
       "         [ 5.9586, -5.3871],\n",
       "         [ 5.9517, -5.4626],\n",
       "         [ 5.8563, -5.5738],\n",
       "         [ 6.0551, -5.2277],\n",
       "         [ 6.0443, -5.4832],\n",
       "         [ 6.0166, -5.3652],\n",
       "         [ 6.0743, -5.3007],\n",
       "         [ 5.9998, -5.6140],\n",
       "         [ 5.9225, -5.1588],\n",
       "         [ 5.7624, -4.9556],\n",
       "         [ 5.8827, -5.3898],\n",
       "         [ 5.2844, -4.6918],\n",
       "         [ 6.0714, -5.5793],\n",
       "         [ 4.5845, -4.1236],\n",
       "         [ 3.7666, -3.3064],\n",
       "         [ 4.8879, -4.3596],\n",
       "         [ 5.0257, -4.5994],\n",
       "         [ 5.3031, -4.5590],\n",
       "         [ 5.9936, -5.3719],\n",
       "         [ 5.3365, -4.3415],\n",
       "         [ 5.4879, -4.9631]],\n",
       "\n",
       "        [[ 5.0095, -4.3673],\n",
       "         [ 5.9596, -5.0883],\n",
       "         [ 6.0597, -5.5439],\n",
       "         [ 5.7482, -5.3882],\n",
       "         [ 5.8401, -5.3136],\n",
       "         [ 5.8983, -5.6192],\n",
       "         [ 5.8309, -5.3598],\n",
       "         [ 5.8338, -5.3755],\n",
       "         [ 5.5744, -5.6376],\n",
       "         [ 5.9285, -5.4554],\n",
       "         [ 5.9588, -5.4549],\n",
       "         [ 5.9309, -5.5381],\n",
       "         [ 5.8183, -5.2806],\n",
       "         [ 5.7523, -5.2411],\n",
       "         [ 5.6050, -5.1971],\n",
       "         [ 5.8689, -5.3685],\n",
       "         [ 5.8297, -5.2127],\n",
       "         [ 5.9920, -5.5044],\n",
       "         [ 5.7659, -5.2597],\n",
       "         [ 5.9153, -5.6761],\n",
       "         [ 6.0364, -5.4230],\n",
       "         [ 6.0153, -5.5478],\n",
       "         [ 5.8629, -5.0284],\n",
       "         [ 5.7728, -5.4023],\n",
       "         [ 5.7777, -5.3083],\n",
       "         [ 5.0099, -4.2470],\n",
       "         [ 5.8629, -5.5165],\n",
       "         [ 3.4780, -2.6040],\n",
       "         [ 4.8757, -4.3407],\n",
       "         [ 5.0687, -4.4566],\n",
       "         [ 5.1222, -4.5083],\n",
       "         [ 5.2106, -4.8382],\n",
       "         [ 3.8357, -3.6271],\n",
       "         [ 5.0988, -4.2982]],\n",
       "\n",
       "        [[ 5.1751, -4.6172],\n",
       "         [ 5.7627, -5.3710],\n",
       "         [ 5.7217, -5.5928],\n",
       "         [ 6.0236, -5.4126],\n",
       "         [ 5.8718, -5.4088],\n",
       "         [ 5.7343, -5.5791],\n",
       "         [ 5.8304, -5.4450],\n",
       "         [ 5.7715, -5.5161],\n",
       "         [ 5.9179, -5.5819],\n",
       "         [ 5.6883, -5.5154],\n",
       "         [ 5.5875, -5.4877],\n",
       "         [ 5.9618, -5.4746],\n",
       "         [ 5.7108, -5.2992],\n",
       "         [ 5.9483, -5.6097],\n",
       "         [ 5.8532, -5.5232],\n",
       "         [ 5.9167, -5.5086],\n",
       "         [ 5.8983, -5.7620],\n",
       "         [ 5.4221, -4.8566],\n",
       "         [ 5.8738, -5.4048],\n",
       "         [ 5.6044, -5.7485],\n",
       "         [ 5.7287, -5.4209],\n",
       "         [ 5.8833, -5.4406],\n",
       "         [ 5.3828, -5.2705],\n",
       "         [ 5.6912, -5.5253],\n",
       "         [ 5.7316, -5.4103],\n",
       "         [ 5.7780, -5.5359],\n",
       "         [ 5.7098, -5.2366],\n",
       "         [ 5.8992, -5.6144],\n",
       "         [ 5.7799, -5.5017],\n",
       "         [ 5.7604, -5.2523],\n",
       "         [ 5.5033, -4.8262],\n",
       "         [ 5.7247, -5.3717],\n",
       "         [ 4.5828, -4.2829],\n",
       "         [ 5.7431, -5.6303]],\n",
       "\n",
       "        [[ 4.8975, -4.1145],\n",
       "         [ 5.9812, -5.2636],\n",
       "         [ 5.6306, -5.1503],\n",
       "         [ 5.5380, -5.0961],\n",
       "         [ 5.4925, -5.0311],\n",
       "         [ 5.6728, -4.8260],\n",
       "         [ 5.2969, -4.6187],\n",
       "         [ 5.4043, -4.7710],\n",
       "         [ 5.5602, -5.0074],\n",
       "         [ 5.6907, -5.2117],\n",
       "         [ 5.3722, -4.8081],\n",
       "         [ 4.6920, -4.0363],\n",
       "         [ 5.8218, -5.1119],\n",
       "         [ 4.9829, -4.7256],\n",
       "         [ 4.8901, -4.2355],\n",
       "         [ 4.2929, -3.9304],\n",
       "         [ 4.9137, -4.3883],\n",
       "         [ 4.6309, -4.2330],\n",
       "         [ 5.0802, -4.7427],\n",
       "         [ 4.6068, -3.9373],\n",
       "         [ 4.6803, -3.9728],\n",
       "         [ 3.2339, -2.6635],\n",
       "         [ 4.8708, -4.2282],\n",
       "         [ 5.5507, -5.0539],\n",
       "         [ 4.6658, -4.0191],\n",
       "         [ 4.6342, -3.7750],\n",
       "         [ 5.0952, -4.5785],\n",
       "         [ 4.9459, -4.0381],\n",
       "         [ 4.9429, -4.6529],\n",
       "         [ 4.6674, -4.2177],\n",
       "         [ 5.3597, -4.8932],\n",
       "         [ 5.0816, -4.4799],\n",
       "         [ 4.9898, -4.6613],\n",
       "         [ 4.6675, -4.5206]]], device='cuda:1', grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(all_tags)):\n",
    "    adapter_name = all_tags[i]\n",
    "    tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "    current_tag = label_ids[:,:, tag_index]\n",
    "\n",
    "\n",
    "    actual = torch.zeros(out[i][0].shape, device = device)\n",
    "\n",
    "    actual[:,:,1] = current_tag\n",
    "    actual[:,:,0] = (current_tag == 0).float()\n",
    "\n",
    "    loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss = loss_fct(out[i][0], actual)\n",
    "\n",
    "    loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8aaa8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 34, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc808e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324ec2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a88f5737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 34])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe729860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae3aaf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 34, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a468f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd4b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7f8e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:48:25.786379Z",
     "start_time": "2021-07-29T07:48:25.786368Z"
    }
   },
   "outputs": [],
   "source": [
    "Epoch = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(Epoch):\n",
    "    all_loss = 0.0\n",
    "    times = 0\n",
    "    for data in trainloader:\n",
    "\n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, label_ids = [t.to(device) for t in data]\n",
    "\n",
    "        out = model(input_ids = tokens_tensors, attention_mask = masks_tensors, segments_tensors = segments_tensors)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for i in range(len(all_tags)):\n",
    "            adapter_name = all_tags[i]\n",
    "            tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "            current_tag = label_ids[:,:, tag_index]\n",
    "\n",
    "\n",
    "            out[i][0].shape\n",
    "\n",
    "            actual = torch.zeros(out[i][0].shape, device = device)\n",
    "\n",
    "            actual[:,:,1] = current_tag\n",
    "            actual[:,:,0] = (current_tag == 0).float()\n",
    "\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "            loss = loss_fct(out[i][0], actual)\n",
    "            all_loss += loss\n",
    "            times += 1\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        print(f\"   Sub: Epoch {epoch}: Loss = {all_loss}, Mean Loss = {all_loss/times}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Loss = {all_loss}, Mean Loss = {all_loss/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b8e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(Epoch):\n",
    "    loss_count = Loss_count()\n",
    "    for data in trainloader:\n",
    "        forward(model, data, model.device, optimizer, loss_count)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"   Sub: Epoch {epoch}: Loss = {loss_count.all_loss}, Mean Loss = {loss_count.all_loss/loss_count.times}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Loss = {all_loss}, Mean Loss = {all_loss/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211157c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547388c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0aa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e508bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfc38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ea919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
