{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64f2ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:55:56.953851Z",
     "start_time": "2021-07-30T02:55:56.947490Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced4b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beafcfe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:55:58.123099Z",
     "start_time": "2021-07-30T02:55:57.535858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.8.1\n",
      "transformers (Adapter) Version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"transformers (Adapter) Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aff5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add515cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:08.456062Z",
     "start_time": "2021-07-30T02:55:58.126238Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215447e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43bfdc87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:08.968757Z",
     "start_time": "2021-07-30T02:56:08.460633Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"./NER_multilabel_data_v2.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda448ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:09.041429Z",
     "start_time": "2021-07-30T02:56:08.971759Z"
    }
   },
   "outputs": [],
   "source": [
    "all_tags = df.newTag\n",
    "\n",
    "all_tags = set(all_tags)\n",
    "\n",
    "all_tags = \"|\".join(all_tags)\n",
    "all_tags = all_tags.split(\"|\")\n",
    "all_tags = set(all_tags)\n",
    "all_tags = list(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d39f8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:09.056497Z",
     "start_time": "2021-07-30T02:56:09.043574Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_csv(data_path):\n",
    "    df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    "    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
    "    tags = df.groupby(\"Sentence #\")[\"newTag\"].apply(list).values\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2799ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:11.267460Z",
     "start_time": "2021-07-30T02:56:09.058608Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences, tags = process_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef80e76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:14.965804Z",
     "start_time": "2021-07-30T02:56:11.272593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['B-art' 'B-eve' 'B-geo' 'B-gpe' 'B-nat' 'B-org' 'B-per' 'B-tim'\n",
      " 'CountryCode' 'CryptoCurrencyCode' 'CurrencyCode' 'Event' 'Float' 'I-art'\n",
      " 'I-eve' 'I-geo' 'I-gpe' 'I-nat' 'I-org' 'I-per' 'I-tim' 'Integer'\n",
      " 'Location' 'Month' 'O' 'Object' 'Party' 'Race' 'SpecialTerm'\n",
      " 'TemporalUnit' 'Time' 'Timezone' 'US_States']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class NER_Dataset(Dataset):\n",
    "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
    "    def __init__(self, mode, tokenizer, data_path, labels):\n",
    "        assert mode in [\"train\", \"test\"]  # 一般訓練你會需要 dev set\n",
    "        self.mode = mode\n",
    "        # 大數據你會需要用 iterator=True\n",
    "        self.sentences, self.tags = process_csv(data_path)\n",
    "        self.len = len(self.sentences)\n",
    "        \n",
    "\n",
    "        if mode != \"test\":\n",
    "            self.label_map = {}\n",
    "            for i in range(len(labels)):\n",
    "                self.label_map[labels[i]] = i\n",
    "                \n",
    "            possible_labels = np.array(range(len(labels))).reshape(-1, 1)\n",
    "            self.oneHotEncoder = OneHotEncoder()\n",
    "            self.oneHotEncoder.fit(possible_labels)\n",
    "        else:\n",
    "            self.label_map = None\n",
    "        \n",
    "        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n",
    "        self.O_label = self.label_map[\"O\"]\n",
    "\n",
    "    \n",
    "    # 定義回傳一筆訓練 / 測試數據的函式\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            label = [\"O\"] + self.tags[idx] + [\"O\"]\n",
    "\n",
    "            label = np.array(label)\n",
    "            label = label.reshape(-1,1)\n",
    "\n",
    "            label = np.apply_along_axis(self.split_one_hot_multiTags, 1, label)\n",
    "            label_tensor = torch.tensor(label, dtype = torch.float32)\n",
    "            \n",
    "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "        word_pieces = ['[CLS]']\n",
    "        word_pieces += self.sentences[idx]\n",
    "        word_pieces += ['[SEP]']\n",
    "        \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # 將第一句包含 [SEP] 的 token 位置設為 0\n",
    "        segments_tensor = torch.zeros_like(tokens_tensor)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def split_one_hot_multiTags(self, tags):\n",
    "        # tags = ['B-org|Party|String']\n",
    "        tags = tags[0]\n",
    "        tags = tags.split(\"|\")\n",
    "\n",
    "\n",
    "        tags_num = list(map(lambda x: self.label_map[x], tags))\n",
    "        #[5, 20, 23]\n",
    "\n",
    "        tags_num = np.array(tags_num).reshape(-1,1)\n",
    "\n",
    "        tags_one_hot = self.oneHotEncoder.transform(tags_num).toarray()\n",
    "\n",
    "        tags_one_hot = tags_one_hot.sum(axis = 0)\n",
    "\n",
    "        #return torch.tensor(tags_one_hot, dtype = torch.float32)\n",
    "\n",
    "        return tags_one_hot\n",
    "    \n",
    "    \n",
    "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "\n",
    "labels = np.unique(\"|\".join(list(df.newTag)).split(\"|\"))\n",
    "print(f\"labels: {labels}\")\n",
    "\n",
    "trainset = NER_Dataset(\"train\", tokenizer=tokenizer, data_path=data_path, labels= labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264f724a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:14.973479Z",
     "start_time": "2021-07-30T02:56:14.967475Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # 測試集有 labels\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = [s[2] for s in samples]\n",
    "        label_ids = pad_sequence(label_ids, \n",
    "                                  batch_first=True)\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40d3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d586897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383271a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c29d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:19.449594Z",
     "start_time": "2021-07-30T02:56:14.975077Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModelWithHeads\n",
    "\n",
    "config = RobertaConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=2,\n",
    ")\n",
    "model = RobertaModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99812659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:20.051177Z",
     "start_time": "2021-07-30T02:56:19.452784Z"
    }
   },
   "outputs": [],
   "source": [
    "for tag in all_tags:\n",
    "    model.add_adapter(tag)\n",
    "    model.add_tagging_head(\n",
    "        tag,\n",
    "        num_labels=2\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6224256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.172554Z",
     "start_time": "2021-07-29T07:47:32.148116Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train_adapter(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc564afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.184115Z",
     "start_time": "2021-07-29T07:47:32.174702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stack[I-tim, SpecialTerm, CryptoCurrencyCode, I-gpe, O, I-nat, Party, Month, Float, B-gpe, B-geo, B-per, I-eve, I-org, Location, Integer, Object, B-org, B-nat, CountryCode, B-art, US_States, Race, I-per, Time, I-geo, Event, B-tim, TemporalUnit, CurrencyCode, Timezone, I-art, B-eve]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac4ccee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.189535Z",
     "start_time": "2021-07-29T07:47:32.185404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-eve'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d88a3f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.193804Z",
     "start_time": "2021-07-29T07:47:32.191309Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers.adapters.composition import Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77cd916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.197565Z",
     "start_time": "2021-07-29T07:47:32.195048Z"
    }
   },
   "outputs": [],
   "source": [
    "parallel = eval(\"Parallel('\" + \"','\".join(all_tags) + \"')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f368a719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.201666Z",
     "start_time": "2021-07-29T07:47:32.198934Z"
    }
   },
   "outputs": [],
   "source": [
    "model.set_active_adapters(parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b887aea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.207008Z",
     "start_time": "2021-07-29T07:47:32.202928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I-tim', 'SpecialTerm', 'CryptoCurrencyCode', 'I-gpe', 'O',\n",
       "       'I-nat', 'Party', 'Month', 'Float', 'B-gpe', 'B-geo', 'B-per',\n",
       "       'I-eve', 'I-org', 'Location', 'Integer', 'Object', 'B-org',\n",
       "       'B-nat', 'CountryCode', 'B-art', 'US_States', 'Race', 'I-per',\n",
       "       'Time', 'I-geo', 'Event', 'B-tim', 'TemporalUnit', 'CurrencyCode',\n",
       "       'Timezone', 'I-art', 'B-eve'], dtype='<U18')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.active_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c3f5b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.211287Z",
     "start_time": "2021-07-29T07:47:32.208313Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04a7442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:32.245131Z",
     "start_time": "2021-07-29T07:47:32.212463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(f\"\"\"\\ntokens_tensors.shape   = {tokens_tensors.shape} \\n{tokens_tensors}\\n------------------------\\nsegments_tensors.shape = {segments_tensors.shape}\\n{segments_tensors}\\n------------------------\\nmasks_tensors.shape    = {masks_tensors.shape}\\n{masks_tensors}\\n------------------------\\nlabel_ids.shape        = {label_ids.shape}\\n{label_ids}\\n\"\"\")'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "\n",
    "tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = data\n",
    "\n",
    "'''print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "------------------------\n",
    "segments_tensors.shape = {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------\n",
    "masks_tensors.shape    = {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "------------------------\n",
    "label_ids.shape        = {label_ids.shape}\n",
    "{label_ids}\n",
    "\"\"\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bc001dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:47:35.059990Z",
     "start_time": "2021-07-29T07:47:32.246954Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd4b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38e5311e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:48:25.782940Z",
     "start_time": "2021-07-29T07:47:35.063129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 3 µs, total: 16 µs\n",
      "Wall time: 28.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CPU times: user 4min 19s, sys: 212 ms, total: 4min 19s\\nWall time: 4min 19s'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"times = 0\n",
    "for data in trainloader:\n",
    "    times += 1\"\"\"\n",
    "\n",
    "\"\"\"CPU times: user 4min 19s, sys: 212 ms, total: 4min 19s\n",
    "Wall time: 4min 19s\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf86df7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:48:25.785423Z",
     "start_time": "2021-07-29T07:48:25.785411Z"
    }
   },
   "outputs": [],
   "source": [
    "times = 11990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851879b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da175050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_count:\n",
    "    def __init__(self):\n",
    "        self.all_loss = 0\n",
    "        self.times = 0\n",
    "    def add(self, i):\n",
    "        self.all_loss += i\n",
    "        self.times += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "159f34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, data, device, optimizer, loss_count):\n",
    "    tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = [t.to(device) for t in data]\n",
    "\n",
    "    out = model(input_ids = tokens_tensors, attention_mask = masks_tensors, segments_tensors = segments_tensors)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(len(all_tags)):\n",
    "        adapter_name = all_tags[i]\n",
    "        tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "        current_tag = label_ids[:,:, tag_index]\n",
    "\n",
    "\n",
    "        out[i][0].shape\n",
    "\n",
    "        actual = torch.zeros(out[i][0].shape, device = device)\n",
    "\n",
    "        actual[:,:,1] = current_tag\n",
    "        actual[:,:,0] = (current_tag == 0).float()\n",
    "\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        loss = loss_fct(out[i][0], actual)\n",
    "        loss_count.add(loss)\n",
    "        if i <= len(all_tags) -1:\n",
    "            loss.backward(retain_graph=True)\n",
    "        else:\n",
    "            loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    del tokens_tensors, segments_tensors, masks_tensors, label_ids, loss, actual, current_tag\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b41aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d213fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b779d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3548675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d1ef698",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1644/1880721193.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "        # \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        out = torch.zeros((tokens_tensors.shape[0], tokens_tensors.shape[1]), device = device).long()\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                        token_type_ids=segments_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=out)\n",
    "\n",
    "        loss = outputs[0][0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # add to batch loss\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28080bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53773368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b92421",
   "metadata": {},
   "source": [
    "# 目前看來外部再算 Loss 的方法行不通，記憶體會炸掉，因此改為試試看，在 Label 的部分做文章，然後選擇性地去 Loss 試試看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6514f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(trainloader))\n",
    "tokens_tensors, segments_tensors, \\\n",
    "masks_tensors, label_ids = [t.to(device) for t in data]\n",
    "\n",
    "out = model(input_ids = tokens_tensors, attention_mask = masks_tensors, segments_tensors = segments_tensors)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "for i in range(len(all_tags)):\n",
    "    adapter_name = all_tags[i]\n",
    "    tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "    current_tag = label_ids[:,:, tag_index]\n",
    "\n",
    "\n",
    "    out[i][0].shape\n",
    "\n",
    "    actual = torch.zeros(out[i][0].shape, device = device)\n",
    "\n",
    "    actual[:,:,1] = current_tag\n",
    "    actual[:,:,0] = (current_tag == 0).float()\n",
    "\n",
    "    loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss = loss_fct(out[i][0], actual)\n",
    "\n",
    "    loss.backward(retain_graph=True)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51b1358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_label = torch.zeros(tokens_tensors.shape, device = device).long()\n",
    "out = model(input_ids = tokens_tensors,\n",
    "            attention_mask = masks_tensors,\n",
    "            segments_tensors = segments_tensors,\n",
    "            labels = tmp_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e4c0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f7841f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_name = all_tags[i]\n",
    "tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "current_tag = label_ids[:,:, tag_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed878106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8a21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2394d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=tensor(2.1799e-05, device='cuda:1', grad_fn=<NllLossBackward>), logits=tensor([[[ 5.3136, -4.6688],\n",
       "         [ 6.2403, -5.2024],\n",
       "         [ 5.9424, -5.2621],\n",
       "         [ 5.9892, -5.3082],\n",
       "         [ 5.8272, -5.3263],\n",
       "         [ 6.0709, -5.7180],\n",
       "         [ 5.7603, -4.9385],\n",
       "         [ 6.1404, -5.1860],\n",
       "         [ 5.9128, -5.0043],\n",
       "         [ 6.0323, -5.4904],\n",
       "         [ 6.1061, -5.1775],\n",
       "         [ 5.8515, -5.1434],\n",
       "         [ 5.5018, -4.7776],\n",
       "         [ 5.9586, -5.3871],\n",
       "         [ 5.9517, -5.4626],\n",
       "         [ 5.8563, -5.5738],\n",
       "         [ 6.0551, -5.2277],\n",
       "         [ 6.0443, -5.4832],\n",
       "         [ 6.0166, -5.3652],\n",
       "         [ 6.0743, -5.3007],\n",
       "         [ 5.9998, -5.6140],\n",
       "         [ 5.9225, -5.1588],\n",
       "         [ 5.7624, -4.9556],\n",
       "         [ 5.8827, -5.3898],\n",
       "         [ 5.2844, -4.6918],\n",
       "         [ 6.0714, -5.5793],\n",
       "         [ 4.5845, -4.1236],\n",
       "         [ 3.7666, -3.3064],\n",
       "         [ 4.8879, -4.3596],\n",
       "         [ 5.0257, -4.5994],\n",
       "         [ 5.3031, -4.5590],\n",
       "         [ 5.9936, -5.3719],\n",
       "         [ 5.3365, -4.3415],\n",
       "         [ 5.4879, -4.9631]],\n",
       "\n",
       "        [[ 5.0095, -4.3673],\n",
       "         [ 5.9596, -5.0883],\n",
       "         [ 6.0597, -5.5439],\n",
       "         [ 5.7482, -5.3882],\n",
       "         [ 5.8401, -5.3136],\n",
       "         [ 5.8983, -5.6192],\n",
       "         [ 5.8309, -5.3598],\n",
       "         [ 5.8338, -5.3755],\n",
       "         [ 5.5744, -5.6376],\n",
       "         [ 5.9285, -5.4554],\n",
       "         [ 5.9588, -5.4549],\n",
       "         [ 5.9309, -5.5381],\n",
       "         [ 5.8183, -5.2806],\n",
       "         [ 5.7523, -5.2411],\n",
       "         [ 5.6050, -5.1971],\n",
       "         [ 5.8689, -5.3685],\n",
       "         [ 5.8297, -5.2127],\n",
       "         [ 5.9920, -5.5044],\n",
       "         [ 5.7659, -5.2597],\n",
       "         [ 5.9153, -5.6761],\n",
       "         [ 6.0364, -5.4230],\n",
       "         [ 6.0153, -5.5478],\n",
       "         [ 5.8629, -5.0284],\n",
       "         [ 5.7728, -5.4023],\n",
       "         [ 5.7777, -5.3083],\n",
       "         [ 5.0099, -4.2470],\n",
       "         [ 5.8629, -5.5165],\n",
       "         [ 3.4780, -2.6040],\n",
       "         [ 4.8757, -4.3407],\n",
       "         [ 5.0687, -4.4566],\n",
       "         [ 5.1222, -4.5083],\n",
       "         [ 5.2106, -4.8382],\n",
       "         [ 3.8357, -3.6271],\n",
       "         [ 5.0988, -4.2982]],\n",
       "\n",
       "        [[ 5.1751, -4.6172],\n",
       "         [ 5.7627, -5.3710],\n",
       "         [ 5.7217, -5.5928],\n",
       "         [ 6.0236, -5.4126],\n",
       "         [ 5.8718, -5.4088],\n",
       "         [ 5.7343, -5.5791],\n",
       "         [ 5.8304, -5.4450],\n",
       "         [ 5.7715, -5.5161],\n",
       "         [ 5.9179, -5.5819],\n",
       "         [ 5.6883, -5.5154],\n",
       "         [ 5.5875, -5.4877],\n",
       "         [ 5.9618, -5.4746],\n",
       "         [ 5.7108, -5.2992],\n",
       "         [ 5.9483, -5.6097],\n",
       "         [ 5.8532, -5.5232],\n",
       "         [ 5.9167, -5.5086],\n",
       "         [ 5.8983, -5.7620],\n",
       "         [ 5.4221, -4.8566],\n",
       "         [ 5.8738, -5.4048],\n",
       "         [ 5.6044, -5.7485],\n",
       "         [ 5.7287, -5.4209],\n",
       "         [ 5.8833, -5.4406],\n",
       "         [ 5.3828, -5.2705],\n",
       "         [ 5.6912, -5.5253],\n",
       "         [ 5.7316, -5.4103],\n",
       "         [ 5.7780, -5.5359],\n",
       "         [ 5.7098, -5.2366],\n",
       "         [ 5.8992, -5.6144],\n",
       "         [ 5.7799, -5.5017],\n",
       "         [ 5.7604, -5.2523],\n",
       "         [ 5.5033, -4.8262],\n",
       "         [ 5.7247, -5.3717],\n",
       "         [ 4.5828, -4.2829],\n",
       "         [ 5.7431, -5.6303]],\n",
       "\n",
       "        [[ 4.8975, -4.1145],\n",
       "         [ 5.9812, -5.2636],\n",
       "         [ 5.6306, -5.1503],\n",
       "         [ 5.5380, -5.0961],\n",
       "         [ 5.4925, -5.0311],\n",
       "         [ 5.6728, -4.8260],\n",
       "         [ 5.2969, -4.6187],\n",
       "         [ 5.4043, -4.7710],\n",
       "         [ 5.5602, -5.0074],\n",
       "         [ 5.6907, -5.2117],\n",
       "         [ 5.3722, -4.8081],\n",
       "         [ 4.6920, -4.0363],\n",
       "         [ 5.8218, -5.1119],\n",
       "         [ 4.9829, -4.7256],\n",
       "         [ 4.8901, -4.2355],\n",
       "         [ 4.2929, -3.9304],\n",
       "         [ 4.9137, -4.3883],\n",
       "         [ 4.6309, -4.2330],\n",
       "         [ 5.0802, -4.7427],\n",
       "         [ 4.6068, -3.9373],\n",
       "         [ 4.6803, -3.9728],\n",
       "         [ 3.2339, -2.6635],\n",
       "         [ 4.8708, -4.2282],\n",
       "         [ 5.5507, -5.0539],\n",
       "         [ 4.6658, -4.0191],\n",
       "         [ 4.6342, -3.7750],\n",
       "         [ 5.0952, -4.5785],\n",
       "         [ 4.9459, -4.0381],\n",
       "         [ 4.9429, -4.6529],\n",
       "         [ 4.6674, -4.2177],\n",
       "         [ 5.3597, -4.8932],\n",
       "         [ 5.0816, -4.4799],\n",
       "         [ 4.9898, -4.6613],\n",
       "         [ 4.6675, -4.5206]]], device='cuda:1', grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(all_tags)):\n",
    "    adapter_name = all_tags[i]\n",
    "    tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "    current_tag = label_ids[:,:, tag_index]\n",
    "\n",
    "\n",
    "    actual = torch.zeros(out[i][0].shape, device = device)\n",
    "\n",
    "    actual[:,:,1] = current_tag\n",
    "    actual[:,:,0] = (current_tag == 0).float()\n",
    "\n",
    "    loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss = loss_fct(out[i][0], actual)\n",
    "\n",
    "    loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9476b23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 34, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90cb5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e539490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d9c7bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 34])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fd54a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "233cd1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 34, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7121f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf56235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d69ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7f8e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:48:25.786379Z",
     "start_time": "2021-07-29T07:48:25.786368Z"
    }
   },
   "outputs": [],
   "source": [
    "Epoch = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(Epoch):\n",
    "    all_loss = 0.0\n",
    "    times = 0\n",
    "    for data in trainloader:\n",
    "\n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, label_ids = [t.to(device) for t in data]\n",
    "\n",
    "        out = model(input_ids = tokens_tensors, attention_mask = masks_tensors, segments_tensors = segments_tensors)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for i in range(len(all_tags)):\n",
    "            adapter_name = all_tags[i]\n",
    "            tag_index = trainset.label_map[adapter_name]\n",
    "\n",
    "            current_tag = label_ids[:,:, tag_index]\n",
    "\n",
    "\n",
    "            out[i][0].shape\n",
    "\n",
    "            actual = torch.zeros(out[i][0].shape, device = device)\n",
    "\n",
    "            actual[:,:,1] = current_tag\n",
    "            actual[:,:,0] = (current_tag == 0).float()\n",
    "\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "            loss = loss_fct(out[i][0], actual)\n",
    "            all_loss += loss\n",
    "            times += 1\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        print(f\"   Sub: Epoch {epoch}: Loss = {all_loss}, Mean Loss = {all_loss/times}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Loss = {all_loss}, Mean Loss = {all_loss/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b8e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(Epoch):\n",
    "    loss_count = Loss_count()\n",
    "    for data in trainloader:\n",
    "        forward(model, data, model.device, optimizer, loss_count)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"   Sub: Epoch {epoch}: Loss = {loss_count.all_loss}, Mean Loss = {loss_count.all_loss/loss_count.times}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Loss = {all_loss}, Mean Loss = {all_loss/times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211157c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547388c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea35621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:48:25.787218Z",
     "start_time": "2021-07-29T07:48:25.787208Z"
    }
   },
   "outputs": [],
   "source": [
    "from telegram_notifier import send_message as telegram_bot_sendtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0aa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e508bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfc38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ea919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
