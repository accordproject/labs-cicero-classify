{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import warnings\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from seqeval.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from simpletransformers.config.model_args import NERArgs\n",
    "from simpletransformers.config.utils import sweep_config_to_sweep_values\n",
    "from simpletransformers.ner.ner_utils import (\n",
    "    InputExample,\n",
    "    LazyNERDataset,\n",
    "    convert_examples_to_features,\n",
    "    get_examples_from_df,\n",
    "    load_hf_dataset,\n",
    "    read_examples_from_file,\n",
    ")\n",
    "\n",
    "from simpletransformers.config.model_args import NERArgs\n",
    "from simpletransformers.config.utils import sweep_config_to_sweep_values\n",
    "from simpletransformers.ner.ner_utils import (\n",
    "    InputExample,\n",
    "    LazyNERDataset,\n",
    "    convert_examples_to_features,\n",
    "    get_examples_from_df,\n",
    "    load_hf_dataset,\n",
    "    read_examples_from_file,\n",
    ")\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers import (\n",
    "    AlbertConfig,\n",
    "    AlbertForTokenClassification,\n",
    "    AlbertTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    BertConfig,\n",
    "    BertForTokenClassification,\n",
    "    BertTokenizer,\n",
    "    BertweetTokenizer,\n",
    "    BigBirdConfig,\n",
    "    BigBirdForTokenClassification,\n",
    "    BigBirdTokenizer,\n",
    "    CamembertConfig,\n",
    "    CamembertForTokenClassification,\n",
    "    CamembertTokenizer,\n",
    "    DebertaConfig,\n",
    "    DebertaForTokenClassification,\n",
    "    DebertaTokenizer,\n",
    "    DebertaV2Config,\n",
    "    DebertaV2ForTokenClassification,\n",
    "    DebertaV2Tokenizer,\n",
    "    DistilBertConfig,\n",
    "    DistilBertForTokenClassification,\n",
    "    DistilBertTokenizer,\n",
    "    ElectraConfig,\n",
    "    ElectraForTokenClassification,\n",
    "    ElectraTokenizer,\n",
    "    LayoutLMConfig,\n",
    "    LayoutLMForTokenClassification,\n",
    "    LayoutLMTokenizer,\n",
    "    LongformerConfig,\n",
    "    LongformerForTokenClassification,\n",
    "    LongformerTokenizer,\n",
    "    MPNetConfig,\n",
    "    MPNetForTokenClassification,\n",
    "    MPNetTokenizer,\n",
    "    MobileBertConfig,\n",
    "    MobileBertForTokenClassification,\n",
    "    MobileBertTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForTokenClassification,\n",
    "    RobertaTokenizerFast,\n",
    "    SqueezeBertConfig,\n",
    "    SqueezeBertForTokenClassification,\n",
    "    SqueezeBertTokenizer,\n",
    "    XLMConfig,\n",
    "    XLMForTokenClassification,\n",
    "    XLMTokenizer,\n",
    "    XLMRobertaConfig,\n",
    "    XLMRobertaForTokenClassification,\n",
    "    XLMRobertaTokenizer,\n",
    "    XLNetConfig,\n",
    "    XLNetForTokenClassification,\n",
    "    XLNetTokenizerFast,\n",
    ")\n",
    "from transformers.convert_graph_to_onnx import convert, quantize\n",
    "from transformers.optimization import AdamW, Adafactor\n",
    "from transformers.optimization import (\n",
    "    get_constant_schedule,\n",
    "    get_constant_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 6.55 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time1 = time.time()\n",
    "\n",
    "from simpletransformers.ner import NERModel\n",
    "# Create a NERModel\n",
    "#model = NERModel('bert', 'bert-base-cased')\n",
    "model = NERModel('bert', 'dslim/bert-base-NER', args={\n",
    "    'learning_rate': 2e-5,\n",
    "    'overwrite_output_dir': True,\n",
    "    'reprocess_input_data': True,\n",
    "    'num_train_epochs': 1,\n",
    "    \"train_batch_size\": 150})\n",
    "\n",
    "print(\"It takes %2.2f seconds\"%(time.time() - time1))\n",
    "origin_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = origin_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c895242370e34a01bc72616a907d1b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71da219e109474b931b4f2636c63585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Prediction', max=2.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-55-8bb2329bb073>, line 194)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-8bb2329bb073>\"\u001b[0;36m, line \u001b[0;32m194\u001b[0m\n\u001b[0;31m    return 0\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "split_on_space=True\n",
    "device = origin_model.device\n",
    "args = origin_model.args\n",
    "pad_token_label_id = origin_model.pad_token_label_id\n",
    "model = origin_model.model\n",
    "\n",
    "\n",
    "preds = None\n",
    "\n",
    "if split_on_space:\n",
    "    if origin_model.args.model_type == \"layoutlm\":\n",
    "        predict_examples = [\n",
    "            InputExample(\n",
    "                i,\n",
    "                sentence.split(),\n",
    "                [origin_model.args.labels_list[0] for word in sentence.split()],\n",
    "                x0,\n",
    "                y0,\n",
    "                x1,\n",
    "                y1,\n",
    "            )\n",
    "            for i, (sentence, x0, y0, x1, y1) in enumerate(to_predict)\n",
    "        ]\n",
    "        to_predict = [sentence for sentence, *_ in to_predict]\n",
    "    else:\n",
    "        predict_examples = [\n",
    "            InputExample(\n",
    "                i,\n",
    "                sentence.split(),\n",
    "                [origin_model.args.labels_list[0] for word in sentence.split()],\n",
    "            )\n",
    "            for i, sentence in enumerate(to_predict)\n",
    "        ]\n",
    "else:\n",
    "    if origin_model.args.model_type == \"layoutlm\":\n",
    "        predict_examples = [\n",
    "            InputExample(\n",
    "                i,\n",
    "                sentence,\n",
    "                [origin_model.args.labels_list[0] for word in sentence],\n",
    "                x0,\n",
    "                y0,\n",
    "                x1,\n",
    "                y1,\n",
    "            )\n",
    "            for i, (sentence, x0, y0, x1, y1) in enumerate(to_predict)\n",
    "        ]\n",
    "        to_predict = [sentence for sentence, *_ in to_predict]\n",
    "    else:\n",
    "        predict_examples = [\n",
    "            InputExample(\n",
    "                i, sentence, [origin_model.args.labels_list[0] for word in sentence]\n",
    "            )\n",
    "            for i, sentence in enumerate(to_predict)\n",
    "        ]\n",
    "\n",
    "if origin_model.args.onnx:\n",
    "\n",
    "    # Encode\n",
    "    model_inputs = origin_model.tokenizer.batch_encode_plus(\n",
    "        to_predict, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    )\n",
    "\n",
    "    # Change shape for batching\n",
    "    encoded_model_inputs = []\n",
    "    if origin_model.args.model_type in [\"bert\", \"xlnet\", \"albert\", \"layoutlm\"]:\n",
    "        for (input_ids, attention_mask, token_type_ids) in tqdm(\n",
    "            zip(\n",
    "                model_inputs[\"input_ids\"],\n",
    "                model_inputs[\"attention_mask\"],\n",
    "                model_inputs[\"token_type_ids\"],\n",
    "            )\n",
    "        ):\n",
    "            encoded_model_inputs.append(\n",
    "                (input_ids, attention_mask, token_type_ids)\n",
    "            )\n",
    "    else:\n",
    "        for (input_ids, attention_mask) in tqdm(\n",
    "            zip(model_inputs[\"input_ids\"], model_inputs[\"attention_mask\"])\n",
    "        ):\n",
    "            encoded_model_inputs.append((input_ids, attention_mask))\n",
    "\n",
    "    # Setup batches\n",
    "    eval_sampler = SequentialSampler(encoded_model_inputs)\n",
    "    eval_dataloader = DataLoader(\n",
    "        encoded_model_inputs,\n",
    "        sampler=eval_sampler,\n",
    "        batch_size=args.eval_batch_size,\n",
    "    )\n",
    "    for batch in tqdm(\n",
    "        eval_dataloader, disable=args.silent, desc=\"Running Prediction\"\n",
    "    ):\n",
    "        if origin_model.args.model_type in [\"bert\", \"xlnet\", \"albert\", \"layoutlm\"]:\n",
    "            inputs_onnx = {\n",
    "                \"input_ids\": batch[0].detach().cpu().numpy(),\n",
    "                \"attention_mask\": batch[1].detach().cpu().numpy(),\n",
    "                \"token_type_ids\": batch[2].detach().cpu().numpy(),\n",
    "            }\n",
    "        else:\n",
    "            inputs_onnx = {\n",
    "                \"input_ids\": batch[0].detach().cpu().numpy(),\n",
    "                \"attention_mask\": batch[1].detach().cpu().numpy(),\n",
    "            }\n",
    "\n",
    "        # Run the model (None = get all the outputs)\n",
    "        output = origin_model.model.run(None, inputs_onnx)\n",
    "\n",
    "        if preds is None:\n",
    "            preds = output[0]\n",
    "            out_input_ids = inputs_onnx[\"input_ids\"]\n",
    "            out_attention_mask = inputs_onnx[\"attention_mask\"]\n",
    "        else:\n",
    "            preds = np.append(preds, output[0], axis=0)\n",
    "            out_input_ids = np.append(\n",
    "                out_input_ids, inputs_onnx[\"input_ids\"], axis=0\n",
    "            )\n",
    "            out_attention_mask = np.append(\n",
    "                out_attention_mask, inputs_onnx[\"attention_mask\"], axis=0\n",
    "            )\n",
    "    out_label_ids = np.zeros_like(out_input_ids)\n",
    "    for index in range(len(out_label_ids)):\n",
    "        out_label_ids[index][0] = -100\n",
    "        out_label_ids[index][-1] = -100\n",
    "else:\n",
    "\n",
    "    eval_dataset = origin_model.load_and_cache_examples(\n",
    "        None, to_predict=predict_examples\n",
    "    )\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size\n",
    "    )\n",
    "\n",
    "    origin_model._move_model_to_device()\n",
    "\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    model.eval()\n",
    "\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    if origin_model.args.fp16:\n",
    "        from torch.cuda import amp\n",
    "\n",
    "    for batch in tqdm(\n",
    "        eval_dataloader, disable=args.silent, desc=\"Running Prediction\"\n",
    "    ):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = origin_model._get_inputs_dict(batch)\n",
    "\n",
    "            if origin_model.args.fp16:\n",
    "                with amp.autocast():\n",
    "                    outputs = model(**inputs)\n",
    "                    tmp_eval_loss, logits = outputs[:2]\n",
    "            else:\n",
    "                outputs = model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "            if origin_model.args.n_gpu > 1:\n",
    "                tmp_eval_loss = tmp_eval_loss.mean()\n",
    "            eval_loss += tmp_eval_loss.item()\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            out_input_ids = inputs[\"input_ids\"].detach().cpu().numpy()\n",
    "            out_attention_mask = inputs[\"attention_mask\"].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(\n",
    "                out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0\n",
    "            )\n",
    "            out_input_ids = np.append(\n",
    "                out_input_ids,\n",
    "                inputs[\"input_ids\"].detach().cpu().numpy(),\n",
    "                axis=0,\n",
    "            )\n",
    "            out_attention_mask = np.append(\n",
    "                out_attention_mask,\n",
    "                inputs[\"attention_mask\"].detach().cpu().numpy(),\n",
    "                axis=0,\n",
    "            )\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "token_logits = preds\n",
    "preds = np.argmax(preds, axis=2)\n",
    "return 0\n",
    "label_map = {i: label for i, label in enumerate(origin_model.args.labels_list)}\n",
    "\n",
    "out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "\n",
    "for i in range(out_label_ids.shape[0]):\n",
    "    for j in range(out_label_ids.shape[1]):\n",
    "        if out_label_ids[i, j] != pad_token_label_id:\n",
    "            out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
    "            preds_list[i].append(label_map[preds[i][j]])\n",
    "\n",
    "if split_on_space:\n",
    "    preds = [\n",
    "        [\n",
    "            {word: preds_list[i][j]}\n",
    "            for j, word in enumerate(sentence.split()[: len(preds_list[i])])\n",
    "        ]\n",
    "        for i, sentence in enumerate(to_predict)\n",
    "    ]\n",
    "else:\n",
    "    preds = [\n",
    "        [\n",
    "            {word: preds_list[i][j]}\n",
    "            for j, word in enumerate(sentence[: len(preds_list[i])])\n",
    "        ]\n",
    "        for i, sentence in enumerate(to_predict)\n",
    "    ]\n",
    "\n",
    "word_tokens = []\n",
    "for n, sentence in enumerate(to_predict):\n",
    "    w_log = origin_model._convert_tokens_to_word_logits(\n",
    "        out_input_ids[n],\n",
    "        out_label_ids[n],\n",
    "        out_attention_mask[n],\n",
    "        token_logits[n],\n",
    "    )\n",
    "    word_tokens.append(w_log)\n",
    "\n",
    "if split_on_space:\n",
    "    model_outputs = [\n",
    "        [\n",
    "            {word: word_tokens[i][j]}\n",
    "            for j, word in enumerate(sentence.split()[: len(preds_list[i])])\n",
    "        ]\n",
    "        for i, sentence in enumerate(to_predict)\n",
    "    ]\n",
    "else:\n",
    "    model_outputs = [\n",
    "        [\n",
    "            {word: word_tokens[i][j]}\n",
    "            for j, word in enumerate(sentence[: len(preds_list[i])])\n",
    "        ]\n",
    "        for i, sentence in enumerate(to_predict)\n",
    "    ]\n",
    "\n",
    "out = preds, model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 128, 9)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 128, 9)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.49  , -0.4907, -0.1362, ..., -0.931 , -1.937 , -0.774 ],\n",
       "       [-0.602 ,  1.201 , -1.62  , ..., -1.763 ,  1.403 , -2.658 ],\n",
       "       [ 1.371 ,  0.6255,  0.287 , ...,  0.3516, -0.6704, -0.8145],\n",
       "       ...,\n",
       "       [ 2.459 ,  0.2203, -1.231 , ..., -1.017 ,  0.2279, -2.223 ],\n",
       "       [ 2.377 ,  0.3005, -1.313 , ..., -1.168 ,  0.373 , -2.236 ],\n",
       "       [ 2.316 ,  0.3474, -1.354 , ..., -1.301 ,  0.4443, -2.197 ]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 0, 5, 5, 0, 0, 5, 5, 5, 0, 5, 5, 0, 0, 5, 5, 0, 0, 5, 5, 0,\n",
       "       0, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 0, 0, 0, 5, 0, 0, 5, 5, 5, 5, 5,\n",
       "       5, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 0,\n",
       "       0, 0, 5, 0, 0, 5, 5, 5, 0, 5, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0,\n",
       "       5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 0, 0, 0, 5, 0, 0, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 0, 5, 5, 0, 0, 0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [[] for _ in range(out_label_ids.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(out_label_ids.shape[0]):\n",
    "    for j in range(out_label_ids.shape[1]):\n",
    "        if out_label_ids[i, j] != pad_token_label_id:\n",
    "            out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
    "            preds_list[i].append(label_map[preds[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B-ORG'], ['O'], ['B-MISC'], ['O'], ['O'], ['O'], ['B-MISC'], ['O'], ['O']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100,    0, -100, ..., -100, -100, -100],\n",
       "       [-100,    0, -100, ..., -100, -100, -100],\n",
       "       [-100,    0, -100, ..., -100, -100, -100],\n",
       "       ...,\n",
       "       [-100,    0, -100, ..., -100, -100, -100],\n",
       "       [-100,    0, -100, ..., -100, -100, -100],\n",
       "       [-100,    0, -100, ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_label_ids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], [], [], [], [], []]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-MISC',\n",
       " 2: 'I-MISC',\n",
       " 3: 'B-PER',\n",
       " 4: 'I-PER',\n",
       " 5: 'B-ORG',\n",
       " 6: 'I-ORG',\n",
       " 7: 'B-LOC',\n",
       " 8: 'I-LOC'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B-ORG'], ['O'], ['B-MISC'], ['O'], ['O'], ['O'], ['B-MISC'], ['O'], ['O']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'EU': 'B-ORG'}],\n",
       " [{'rejects': 'O'}],\n",
       " [{'German': 'B-MISC'}],\n",
       " [{'call': 'O'}],\n",
       " [{'to': 'O'}],\n",
       " [{'boycott': 'O'}],\n",
       " [{'British': 'B-MISC'}],\n",
       " [{'lamb': 'O'}],\n",
       " [{'.': 'O'}]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{'EU': 'B-ORG'}],\n",
       "  [{'rejects': 'O'}],\n",
       "  [{'German': 'B-MISC'}],\n",
       "  [{'call': 'O'}],\n",
       "  [{'to': 'O'}],\n",
       "  [{'boycott': 'O'}],\n",
       "  [{'British': 'B-MISC'}],\n",
       "  [{'lamb': 'O'}],\n",
       "  [{'.': 'O'}]],\n",
       " [[{'EU': [[-0.602,\n",
       "      1.201,\n",
       "      -1.62,\n",
       "      -1.256,\n",
       "      -2.738,\n",
       "      7.86,\n",
       "      -1.763,\n",
       "      1.403,\n",
       "      -2.658]]}],\n",
       "  [{'rejects': [[10.41,\n",
       "      -1.088,\n",
       "      -1.182,\n",
       "      -1.353,\n",
       "      -2.336,\n",
       "      -0.596,\n",
       "      -1.522,\n",
       "      -1.652,\n",
       "      -1.679]]}],\n",
       "  [{'German': [[-0.4705,\n",
       "      9.375,\n",
       "      1.095,\n",
       "      -1.97,\n",
       "      -1.378,\n",
       "      -1.261,\n",
       "      -2.059,\n",
       "      -1.479,\n",
       "      -1.738]]}],\n",
       "  [{'call': [[8.25,\n",
       "      -0.9697,\n",
       "      -2.928,\n",
       "      -0.985,\n",
       "      -2.43,\n",
       "      -0.2115,\n",
       "      -1.676,\n",
       "      0.2286,\n",
       "      -2.107]]}],\n",
       "  [{'to': [[9.4,\n",
       "      -1.037,\n",
       "      -1.727,\n",
       "      -1.475,\n",
       "      -2.574,\n",
       "      -0.5625,\n",
       "      -1.587,\n",
       "      -1.129,\n",
       "      -1.731]]}],\n",
       "  [{'boycott': [[9.74,\n",
       "      -0.221,\n",
       "      -1.785,\n",
       "      -1.018,\n",
       "      -3.016,\n",
       "      -0.1761,\n",
       "      -1.995,\n",
       "      -0.8857,\n",
       "      -2.285]]}],\n",
       "  [{'British': [[-1.268,\n",
       "      9.31,\n",
       "      1.049,\n",
       "      -2.008,\n",
       "      -1.551,\n",
       "      -0.8687,\n",
       "      -2.236,\n",
       "      -1.353,\n",
       "      -1.893]]}],\n",
       "  [{'lamb': [[9.11,\n",
       "      -0.4636,\n",
       "      -1.887,\n",
       "      -0.768,\n",
       "      -3.271,\n",
       "      -0.991,\n",
       "      -1.444,\n",
       "      -1.039,\n",
       "      -1.614],\n",
       "     [7.934,\n",
       "      -0.296,\n",
       "      -1.155,\n",
       "      -1.996,\n",
       "      -2.088,\n",
       "      -1.448,\n",
       "      -1.417,\n",
       "      -1.228,\n",
       "      -1.176]]}],\n",
       "  [{'.': [[9.164,\n",
       "      -1.847,\n",
       "      -2.322,\n",
       "      -0.4004,\n",
       "      -2.271,\n",
       "      -1.202,\n",
       "      -1.774,\n",
       "      -0.59,\n",
       "      -1.3]]}]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple",
   "language": "python",
   "name": "simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
