{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前進度：我在閱讀 SimpleTransformer 的仔入資料的程式碼並嘗試複製<br>\n",
    "因為我要把它改為多標籤的資料<br>\n",
    "但我看不太懂，還在努力中\n",
    "\n",
    "多花一點時間相信我可以掌握，加油\n",
    "\n",
    "0623 19:00 進度<br>\n",
    "我把關鍵的部分抓出來了，load_and_cache_examples 就是把檔名轉為 Tensor 的部分！明天繼續"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import warnings\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from seqeval.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from simpletransformers.config.model_args import NERArgs\n",
    "from simpletransformers.config.utils import sweep_config_to_sweep_values\n",
    "from simpletransformers.ner.ner_utils import (\n",
    "    InputExample,\n",
    "    LazyNERDataset,\n",
    "    convert_examples_to_features,\n",
    "    get_examples_from_df,\n",
    "    load_hf_dataset,\n",
    "    read_examples_from_file,\n",
    ")\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers import (\n",
    "    AlbertConfig,\n",
    "    AlbertForTokenClassification,\n",
    "    AlbertTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    BertConfig,\n",
    "    BertForTokenClassification,\n",
    "    BertTokenizer,\n",
    "    BertweetTokenizer,\n",
    "    BigBirdConfig,\n",
    "    BigBirdForTokenClassification,\n",
    "    BigBirdTokenizer,\n",
    "    CamembertConfig,\n",
    "    CamembertForTokenClassification,\n",
    "    CamembertTokenizer,\n",
    "    DebertaConfig,\n",
    "    DebertaForTokenClassification,\n",
    "    DebertaTokenizer,\n",
    "    DebertaV2Config,\n",
    "    DebertaV2ForTokenClassification,\n",
    "    DebertaV2Tokenizer,\n",
    "    DistilBertConfig,\n",
    "    DistilBertForTokenClassification,\n",
    "    DistilBertTokenizer,\n",
    "    ElectraConfig,\n",
    "    ElectraForTokenClassification,\n",
    "    ElectraTokenizer,\n",
    "    LayoutLMConfig,\n",
    "    LayoutLMForTokenClassification,\n",
    "    LayoutLMTokenizer,\n",
    "    LongformerConfig,\n",
    "    LongformerForTokenClassification,\n",
    "    LongformerTokenizer,\n",
    "    MPNetConfig,\n",
    "    MPNetForTokenClassification,\n",
    "    MPNetTokenizer,\n",
    "    MobileBertConfig,\n",
    "    MobileBertForTokenClassification,\n",
    "    MobileBertTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForTokenClassification,\n",
    "    RobertaTokenizerFast,\n",
    "    SqueezeBertConfig,\n",
    "    SqueezeBertForTokenClassification,\n",
    "    SqueezeBertTokenizer,\n",
    "    XLMConfig,\n",
    "    XLMForTokenClassification,\n",
    "    XLMTokenizer,\n",
    "    XLMRobertaConfig,\n",
    "    XLMRobertaForTokenClassification,\n",
    "    XLMRobertaTokenizer,\n",
    "    XLNetConfig,\n",
    "    XLNetForTokenClassification,\n",
    "    XLNetTokenizerFast,\n",
    ")\n",
    "from transformers.convert_graph_to_onnx import convert, quantize\n",
    "from transformers.optimization import AdamW, Adafactor\n",
    "from transformers.optimization import (\n",
    "    get_constant_schedule,\n",
    "    get_constant_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from simpletransformers.ner import NERModel\n",
    "# Create a NERModel\n",
    "#model = NERModel('bert', 'bert-base-cased')\n",
    "model = NERModel('bert', 'dslim/bert-base-NER', args={\n",
    "    'learning_rate': 2e-5,\n",
    "    'overwrite_output_dir': True,\n",
    "    'reprocess_input_data': True,\n",
    "    'num_train_epochs': 1,\n",
    "    \"train_batch_size\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./train.txt\"\n",
    "out = []\n",
    "with open(file) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    \n",
    "for i in range(len(lines)):\n",
    "    out.append(\" \".join(lines[i].replace(\"\\n\", \"\").split(\" \")[:-1] + [\"O\\n\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-DOCSTART- -X- -X- O\\n',\n",
       " 'O\\n',\n",
       " 'EU NNP B-NP O\\n',\n",
       " 'rejects VBZ B-VP O\\n',\n",
       " 'German JJ B-NP O\\n',\n",
       " 'call NN I-NP O\\n',\n",
       " 'to TO B-VP O\\n',\n",
       " 'boycott VB I-VP O\\n',\n",
       " 'British JJ B-NP O\\n',\n",
       " 'lamb NN I-NP O\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./test_test.txt\", \"w\") as f:\n",
    "    f.writelines(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-DOCSTART- -X- -X- O\\n',\n",
       " '\\n',\n",
       " 'EU NNP B-NP B-ORG\\n',\n",
       " 'rejects VBZ B-VP O\\n',\n",
       " 'German JJ B-NP B-MISC\\n',\n",
       " 'call NN I-NP O\\n',\n",
       " 'to TO B-VP O\\n',\n",
       " 'boycott VB I-VP O\\n',\n",
       " 'British JJ B-NP B-MISC\\n',\n",
       " 'lamb NN I-NP O\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['German', 'JJ', 'B-NP']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[4].replace(\"\\n\", \"\").split(\" \")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German JJ B-NP O\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(lines[4].replace(\"\\n\", \"\").split(\" \")[:-1] + [\"O\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 CD I-NP O\\n', '\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8667, 102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8667, 1291, 142, 2225, 1320, 102]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello World Eason\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1291, 102]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 142, 2225, 1320, 102]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Eason\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "MODELS_WITH_EXTRA_SEP_TOKEN = [\n",
    "    \"roberta\",\n",
    "    \"camembert\",\n",
    "    \"xlmroberta\",\n",
    "    \"longformer\",\n",
    "    \"mpnet\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a322d946e2942dea2a28dc0952ea5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = \"./train.txt\"\n",
    "evaluate=False\n",
    "no_cache=False\n",
    "to_predict=None\n",
    "\n",
    "process_count = model.args.process_count\n",
    "\n",
    "tokenizer = model.tokenizer\n",
    "args = model.args\n",
    "\n",
    "if not no_cache:\n",
    "    no_cache = args.no_cache\n",
    "\n",
    "mode = \"dev\" if evaluate else \"train\"\n",
    "if model.args.use_hf_datasets and data is not None:\n",
    "    if model.args.model_type == \"layoutlm\":\n",
    "        raise NotImplementedError(\n",
    "            \"HuggingFace Datasets support is not implemented for LayoutLM models\"\n",
    "        )\n",
    "    dataset = load_hf_dataset(\n",
    "        data,\n",
    "        model.args.labels_list,\n",
    "        model.args.max_seq_length,\n",
    "        model.tokenizer,\n",
    "        # XLNet has a CLS token at the end\n",
    "        cls_token_at_end=bool(args.model_type in [\"xlnet\"]),\n",
    "        cls_token=tokenizer.cls_token_id,\n",
    "        cls_token_segment_id=2 if args.model_type in [\"xlnet\"] else 0,\n",
    "        sep_token=tokenizer.sep_token_id,\n",
    "        # RoBERTa uses an extra separator b/w pairs of sentences,\n",
    "        # cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "        sep_token_extra=args.model_type in MODELS_WITH_EXTRA_SEP_TOKEN,\n",
    "        # PAD on the left for XLNet\n",
    "        pad_on_left=bool(args.model_type in [\"xlnet\"]),\n",
    "        pad_token=tokenizer.pad_token_id,\n",
    "        pad_token_segment_id=4 if args.model_type in [\"xlnet\"] else 0,\n",
    "        pad_token_label_id=model.pad_token_label_id,\n",
    "        silent=args.silent,\n",
    "        args=model.args,\n",
    "    )\n",
    "else:\n",
    "    if not to_predict and isinstance(data, str) and model.args.lazy_loading:\n",
    "        dataset = LazyNERDataset(data, tokenizer, model.args)\n",
    "    else:\n",
    "        if to_predict:\n",
    "            examples = to_predict\n",
    "            no_cache = True\n",
    "        else:\n",
    "            if isinstance(data, str):\n",
    "                examples = read_examples_from_file(\n",
    "                    data,\n",
    "                    mode,\n",
    "                    bbox=True if model.args.model_type == \"layoutlm\" else False,\n",
    "                )\n",
    "            else:\n",
    "                if model.args.lazy_loading:\n",
    "                    raise ValueError(\n",
    "                        \"Input must be given as a path to a file when using lazy loading\"\n",
    "                    )\n",
    "                examples = get_examples_from_df(\n",
    "                    data,\n",
    "                    bbox=True if model.args.model_type == \"layoutlm\" else False,\n",
    "                )\n",
    "\n",
    "        cached_features_file = os.path.join(\n",
    "            args.cache_dir,\n",
    "            \"cached_{}_{}_{}_{}_{}\".format(\n",
    "                mode,\n",
    "                args.model_type,\n",
    "                args.max_seq_length,\n",
    "                model.num_labels,\n",
    "                len(examples),\n",
    "            ),\n",
    "        )\n",
    "        if not no_cache:\n",
    "            os.makedirs(model.args.cache_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(cached_features_file) and (\n",
    "            (not args.reprocess_input_data and not no_cache)\n",
    "            or (\n",
    "                mode == \"dev\" and args.use_cached_eval_features and not no_cache\n",
    "            )\n",
    "        ):\n",
    "            features = torch.load(cached_features_file)\n",
    "            logger.info(\n",
    "                f\" Features loaded from cache at {cached_features_file}\"\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\" Converting to features started.\")\n",
    "            features = convert_examples_to_features(\n",
    "                examples,\n",
    "                model.args.labels_list,\n",
    "                model.args.max_seq_length,\n",
    "                model.tokenizer,\n",
    "                # XLNet has a CLS token at the end\n",
    "                cls_token_at_end=bool(args.model_type in [\"xlnet\"]),\n",
    "                cls_token=tokenizer.cls_token,\n",
    "                cls_token_segment_id=2 if args.model_type in [\"xlnet\"] else 0,\n",
    "                sep_token=tokenizer.sep_token,\n",
    "                # RoBERTa uses an extra separator b/w pairs of sentences,\n",
    "                # cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "                sep_token_extra=args.model_type in MODELS_WITH_EXTRA_SEP_TOKEN,\n",
    "                # PAD on the left for XLNet\n",
    "                pad_on_left=bool(args.model_type in [\"xlnet\"]),\n",
    "                pad_token=tokenizer.pad_token_id,\n",
    "                pad_token_segment_id=4 if args.model_type in [\"xlnet\"] else 0,\n",
    "                pad_token_label_id=model.pad_token_label_id,\n",
    "                process_count=process_count,\n",
    "                silent=args.silent,\n",
    "                use_multiprocessing=args.use_multiprocessing,\n",
    "                chunksize=args.multiprocessing_chunksize,\n",
    "                mode=mode,\n",
    "                use_multiprocessing_for_evaluation=args.use_multiprocessing_for_evaluation,\n",
    "            )\n",
    "\n",
    "            if not no_cache:\n",
    "                torch.save(features, cached_features_file)\n",
    "\n",
    "        all_input_ids = torch.tensor(\n",
    "            [f.input_ids for f in features], dtype=torch.long\n",
    "        )\n",
    "        all_input_mask = torch.tensor(\n",
    "            [f.input_mask for f in features], dtype=torch.long\n",
    "        )\n",
    "        all_segment_ids = torch.tensor(\n",
    "            [f.segment_ids for f in features], dtype=torch.long\n",
    "        )\n",
    "        all_label_ids = torch.tensor(\n",
    "            [f.label_ids for f in features], dtype=torch.long\n",
    "        )\n",
    "\n",
    "        if model.args.model_type == \"layoutlm\":\n",
    "            all_bboxes = torch.tensor(\n",
    "                [f.bboxes for f in features], dtype=torch.long\n",
    "            )\n",
    "\n",
    "        if model.args.onnx:\n",
    "            out_return = all_label_ids\n",
    "\n",
    "        if model.args.model_type == \"layoutlm\":\n",
    "            dataset = TensorDataset(\n",
    "                all_input_ids,\n",
    "                all_input_mask,\n",
    "                all_segment_ids,\n",
    "                all_label_ids,\n",
    "                all_bboxes,\n",
    "            )\n",
    "        else:\n",
    "            dataset = TensorDataset(\n",
    "                all_input_ids, all_input_mask, all_segment_ids, all_label_ids\n",
    "            )\n",
    "\n",
    "out_return =  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7ff18c867810>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple",
   "language": "python",
   "name": "simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
