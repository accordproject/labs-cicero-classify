{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iYLQO5Evvqy"
   },
   "source": [
    "# Training a `Robust' Adapter with AdapterDrop\n",
    "\n",
    "This notebook extends our quickstart adapter training notebook to illustrate how we can use AdapterDrop\n",
    "to robustly train an adapter, i.e. adapters that allow us to dynmically dropp layers for faster multi-task inference.\n",
    "Please have a look at the original adapter training notebook for more details on the setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-XTIOLv0isn"
   },
   "source": [
    "## Installation\n",
    "\n",
    "First, let's install the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Mx916lBCfoL",
    "outputId": "bec39206-a7d9-415a-a3fa-90b948d51489",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/home/eason/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/e06abb624abab47e1a64608fdfe65a913f5a68c66118408032644a3285208fb5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae7ee7daf46470cb4292902162f0d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885e0798b30e48d6b8cc0d2950bc703d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6636e626ee52405e8c4a46bad1833c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eason/data/anaconda3/envs/adapter/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: rename_column_ is deprecated and will be removed in the next major version of datasets. Use DatasetDict.rename_column instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Encode the input data\n",
    "dataset = dataset.map(encode_batch, batched=True)\n",
    "# The transformers model expects the target class column to be named \"labels\"\n",
    "dataset.rename_column_(\"label\", \"labels\")\n",
    "# Transform to pytorch tensors and only output the required columns\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2-2CbfPGYvi"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tp9uG-pT-qgv",
    "outputId": "c6a19f25-26b9-44c7-887c-1d1a71e957fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModelWithHeads\n",
    "\n",
    "config = RobertaConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=2,\n",
    "    id2label={ 0: \"ðŸ‘Ž\", 1: \"ðŸ‘\"},\n",
    ")\n",
    "model = RobertaModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Add a new adapter\n",
    "model.add_adapter(\"rotten_tomatoes\")\n",
    "# Add a matching classification head\n",
    "model.add_classification_head(\"rotten_tomatoes\", num_labels=2)\n",
    "# Activate the adapter\n",
    "model.train_adapter(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev5t_8i8HzJB"
   },
   "source": [
    "To dynamically drop adapter layers during training, we make use of HuggingFace's `TrainerCallback'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.roberta.modeling_roberta.RobertaModelWithHeads"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5FRft_5AAlQd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction, TrainerCallback\n",
    "\n",
    "class AdapterDropTrainerCallback(TrainerCallback):\n",
    "  def on_step_begin(self, args, state, control, **kwargs):\n",
    "    skip_layers = list(range(np.random.randint(0, 11)))\n",
    "    skip_layers = None\n",
    "    kwargs['model'].set_active_adapters(\"rotten_tomatoes\", skip_layers=skip_layers)\n",
    "\n",
    "  def on_evaluate(self, args, state, control, **kwargs):\n",
    "    # Deactivate skipping layers during evaluation (otherwise it would use the\n",
    "    # previous randomly chosen skip_layers and thus yield results not comparable\n",
    "    # across different epochs)\n",
    "    kwargs['model'].set_active_adapters(\"rotten_tomatoes\", skip_layers=None)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=200,\n",
    "    output_dir=\"./training_output\",\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "\n",
    "trainer.add_callback(AdapterDropTrainerCallback())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iHhoYuLIdX3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now train and evaluate our robustly trained adapter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "zZxaujENntNR",
    "outputId": "6700e4ac-1258-4bd8-ac30-a578c8d6c4ba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eason/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='804' max='804' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [804/804 02:58, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.447900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.246900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eason/data/anaconda3/envs/adapter/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27976980805397034,\n",
       " 'eval_acc': 0.8855534709193246,\n",
       " 'eval_runtime': 1.7413,\n",
       " 'eval_samples_per_second': 612.177,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Adapter_Drop_Training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
