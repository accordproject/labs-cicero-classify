{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64f2ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:25.771051Z",
     "start_time": "2021-07-30T08:10:25.423378Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced4b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beafcfe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:26.238241Z",
     "start_time": "2021-07-30T08:10:25.773029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.8.1\n",
      "transformers (Adapter) Version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"transformers (Adapter) Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aff5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add515cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:35.557747Z",
     "start_time": "2021-07-30T08:10:26.244303Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215447e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43bfdc87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:36.111274Z",
     "start_time": "2021-07-30T08:10:35.560376Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"./NER_multilabel_data_v2.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "all_tags = df.newTag\n",
    "\n",
    "all_tags = set(all_tags)\n",
    "\n",
    "all_tags = \"|\".join(all_tags)\n",
    "all_tags = all_tags.split(\"|\")\n",
    "all_tags = set(all_tags)\n",
    "all_tags = list(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d39f8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:38.303247Z",
     "start_time": "2021-07-30T08:10:36.113148Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_csv(data_path):\n",
    "    df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    "    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
    "    tags = df.groupby(\"Sentence #\")[\"newTag\"].apply(list).values\n",
    "    return sentences, tags\n",
    "\n",
    "sentences, tags = process_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef80e76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:41.992289Z",
     "start_time": "2021-07-30T08:10:38.305714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['B-art' 'B-eve' 'B-geo' 'B-gpe' 'B-nat' 'B-org' 'B-per' 'B-tim'\n",
      " 'CountryCode' 'CryptoCurrencyCode' 'CurrencyCode' 'Event' 'Float' 'I-art'\n",
      " 'I-eve' 'I-geo' 'I-gpe' 'I-nat' 'I-org' 'I-per' 'I-tim' 'Integer'\n",
      " 'Location' 'Month' 'O' 'Object' 'Party' 'Race' 'SpecialTerm'\n",
      " 'TemporalUnit' 'Time' 'Timezone' 'US_States']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class NER_Dataset(Dataset):\n",
    "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
    "    def __init__(self, mode, tokenizer, data_path, labels):\n",
    "        assert mode in [\"train\", \"test\"]  # 一般訓練你會需要 dev set\n",
    "        self.mode = mode\n",
    "        # 大數據你會需要用 iterator=True\n",
    "        self.sentences, self.tags = process_csv(data_path)\n",
    "        self.len = len(self.sentences)\n",
    "        \n",
    "\n",
    "        if mode != \"test\":\n",
    "            self.label_map = {}\n",
    "            for i in range(len(labels)):\n",
    "                self.label_map[labels[i]] = i\n",
    "                \n",
    "            possible_labels = np.array(range(len(labels))).reshape(-1, 1)\n",
    "            self.oneHotEncoder = OneHotEncoder()\n",
    "            self.oneHotEncoder.fit(possible_labels)\n",
    "        else:\n",
    "            self.label_map = None\n",
    "        \n",
    "        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n",
    "        self.O_label = self.label_map[\"O\"]\n",
    "\n",
    "    \n",
    "    # 定義回傳一筆訓練 / 測試數據的函式\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            label = [\"O\"] + self.tags[idx] + [\"O\"]\n",
    "\n",
    "            label = np.array(label)\n",
    "            label = label.reshape(-1,1)\n",
    "\n",
    "            label = np.apply_along_axis(self.split_one_hot_multiTags, 1, label)\n",
    "            label_tensor = torch.tensor(label, dtype = torch.float32)\n",
    "            \n",
    "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "        word_pieces = ['[CLS]']\n",
    "        word_pieces += self.sentences[idx]\n",
    "        word_pieces += ['[SEP]']\n",
    "        \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # 將第一句包含 [SEP] 的 token 位置設為 0\n",
    "        segments_tensor = torch.zeros_like(tokens_tensor)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def split_one_hot_multiTags(self, tags):\n",
    "        # tags = ['B-org|Party|String']\n",
    "        tags = tags[0]\n",
    "        tags = tags.split(\"|\")\n",
    "\n",
    "\n",
    "        tags_num = list(map(lambda x: self.label_map[x], tags))\n",
    "        #[5, 20, 23]\n",
    "\n",
    "        tags_num = np.array(tags_num).reshape(-1,1)\n",
    "\n",
    "        tags_one_hot = self.oneHotEncoder.transform(tags_num).toarray()\n",
    "\n",
    "        tags_one_hot = tags_one_hot.sum(axis = 0)\n",
    "\n",
    "        #return torch.tensor(tags_one_hot, dtype = torch.float32)\n",
    "\n",
    "        return tags_one_hot\n",
    "    \n",
    "    \n",
    "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "\n",
    "labels = np.unique(\"|\".join(list(df.newTag)).split(\"|\"))\n",
    "print(f\"labels: {labels}\")\n",
    "\n",
    "trainset = NER_Dataset(\"train\", tokenizer=tokenizer, data_path=data_path, labels= labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264f724a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:41.999378Z",
     "start_time": "2021-07-30T08:10:41.993773Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # 測試集有 labels\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = [s[2] for s in samples]\n",
    "        label_ids = pad_sequence(label_ids, \n",
    "                                  batch_first=True)\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40d3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d586897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d383271a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:42.004104Z",
     "start_time": "2021-07-30T08:10:42.000761Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset.id2label = {}\n",
    "for key in trainset.label_map.keys():\n",
    "    trainset.id2label[trainset.label_map[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b00c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c29d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:46.466858Z",
     "start_time": "2021-07-30T08:10:42.006385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModelWithHeads\n",
    "\n",
    "config = RobertaConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=len(all_tags),\n",
    "    label2id = trainset.label_map, \n",
    "    id2label = trainset.id2label\n",
    ")\n",
    "model = RobertaModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af991b5d",
   "metadata": {},
   "source": [
    "name = model.load_adapter(\"./save_adapters/ALL_tag_0730\")\n",
    "model.add_tagging_head(\n",
    "        name,\n",
    "        num_labels=len(trainset.label_map.keys()), overwrite_ok=True\n",
    "      )\n",
    "model.train_adapter(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c3f5b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:46.471763Z",
     "start_time": "2021-07-30T08:10:46.468679Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ef36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f04a7442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:48.062379Z",
     "start_time": "2021-07-30T08:10:46.473471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(f\"\"\"\\ntokens_tensors.shape   = {tokens_tensors.shape} \\n{tokens_tensors}\\n------------------------\\nsegments_tensors.shape = {segments_tensors.shape}\\n{segments_tensors}\\n------------------------\\nmasks_tensors.shape    = {masks_tensors.shape}\\n{masks_tensors}\\n------------------------\\nlabel_ids.shape        = {label_ids.shape}\\n{label_ids}\\n\"\"\")'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "\n",
    "tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = data\n",
    "\n",
    "'''print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "------------------------\n",
    "segments_tensors.shape = {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------\n",
    "masks_tensors.shape    = {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "------------------------\n",
    "label_ids.shape        = {label_ids.shape}\n",
    "{label_ids}\n",
    "\"\"\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87806f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:45:33.798236Z",
     "start_time": "2021-07-30T07:45:33.791209Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac2ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae251852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:49:00.550764Z",
     "start_time": "2021-07-30T07:49:00.533260Z"
    }
   },
   "source": [
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                    \"weight_decay\": 1e-5,\n",
    "                },\n",
    "                {\n",
    "                    \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                    \"weight_decay\": 0.0,\n",
    "                },\n",
    "            ]\n",
    "optimizer = torch.optim.AdamW(params=optimizer_grouped_parameters, lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a46bbb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:48.068316Z",
     "start_time": "2021-07-30T08:10:48.064089Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f54432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:48.073538Z",
     "start_time": "2021-07-30T08:10:48.069956Z"
    }
   },
   "outputs": [],
   "source": [
    "all_tags = ['Float','TemporalUnit','I-gpe','CountryCode','CurrencyCode','Timezone','CryptoCurrencyCode','Month','Party','B-tim','I-art','Time','B-per','B-gpe','B-geo','O','Location','Event','I-nat','Race','B-org','I-geo','I-tim','I-eve','SpecialTerm','B-art','US_States','B-eve','I-org','B-nat','Object','I-per','Integer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef1b1ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T08:13:28.767727Z",
     "start_time": "2021-07-31T08:13:28.675280Z"
    }
   },
   "outputs": [],
   "source": [
    "from telegram_notifier import send_message as telegram_bot_sendtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "177b6202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:10:50.731140Z",
     "start_time": "2021-07-30T08:10:48.080135Z"
    }
   },
   "outputs": [],
   "source": [
    "train_id = 0\n",
    "device = torch.device(f\"cuda:{train_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6356a4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skip Float.\n",
      "\n",
      "\n",
      "TemporalUnit: epoch 0\n",
      "\tLoss: 0.5391535758972168\n",
      "\tLoss: 0.5389758348464966\n",
      "\tLoss: 0.5388613343238831\n",
      "\tLoss: 0.5377902388572693\n",
      "\tLoss: 0.5413982272148132\n",
      "\tLoss: 0.5388877987861633\n",
      "\tLoss: 0.5381402969360352\n",
      "\tLoss: 0.5406540036201477\n",
      "\tLoss: 0.5400776863098145\n",
      "\tLoss: 0.5401015281677246\n",
      "\tLoss: 0.5411549210548401\n",
      "\tLoss: 0.5415317416191101\n",
      "\tLoss: 0.5394170880317688\n",
      "\tLoss: 0.5425978899002075\n",
      "\tLoss: 0.5405617952346802\n",
      "\tLoss: 0.5384573936462402\n",
      "\tLoss: 0.5415876507759094\n",
      "\tLoss: 0.5379591584205627\n",
      "\tLoss: 0.5425953269004822\n",
      "\n",
      "TemporalUnit: epoch 1\n",
      "\tLoss: 0.5402517914772034\n",
      "\tLoss: 0.5376653075218201\n",
      "\tLoss: 0.5391207337379456\n",
      "\tLoss: 0.5397608876228333\n",
      "\tLoss: 0.5389649271965027\n",
      "\tLoss: 0.5378719568252563\n",
      "\tLoss: 0.5390498042106628\n",
      "\tLoss: 0.5396788120269775\n",
      "\tLoss: 0.5404996871948242\n",
      "\tLoss: 0.5411071181297302\n",
      "\tLoss: 0.5388025641441345\n",
      "\tLoss: 0.5425803661346436\n",
      "\tLoss: 0.5401619076728821\n",
      "\tLoss: 0.5422891974449158\n",
      "\tLoss: 0.5396026372909546\n",
      "\tLoss: 0.5394212603569031\n",
      "\tLoss: 0.5414801239967346\n",
      "\tLoss: 0.5367273092269897\n",
      "\tLoss: 0.5405068397521973\n",
      "\n",
      "Skip I-gpe.\n",
      "\n",
      "\n",
      "CountryCode: epoch 0\n",
      "\tLoss: 0.47118762135505676\n",
      "\tLoss: 0.47100239992141724\n",
      "\tLoss: 0.474043607711792\n",
      "\tLoss: 0.47294819355010986\n",
      "\tLoss: 0.4739682376384735\n",
      "\tLoss: 0.47294676303863525\n",
      "\tLoss: 0.4718738794326782\n",
      "\tLoss: 0.47643348574638367\n",
      "\tLoss: 0.47342002391815186\n",
      "\tLoss: 0.4737986922264099\n",
      "\tLoss: 0.4734257459640503\n",
      "\tLoss: 0.47593197226524353\n",
      "\tLoss: 0.4717061519622803\n",
      "\tLoss: 0.4757401943206787\n",
      "\tLoss: 0.47266095876693726\n",
      "\tLoss: 0.4744229316711426\n",
      "\tLoss: 0.4749106168746948\n",
      "\tLoss: 0.47319331765174866\n",
      "\tLoss: 0.47380951046943665\n",
      "\n",
      "CountryCode: epoch 1\n",
      "\tLoss: 0.4719647169113159\n",
      "\tLoss: 0.47432926297187805\n",
      "\tLoss: 0.47438958287239075\n",
      "\tLoss: 0.4728391766548157\n",
      "\tLoss: 0.4732776880264282\n",
      "\tLoss: 0.47346967458724976\n",
      "\tLoss: 0.47374609112739563\n",
      "\tLoss: 0.4758458733558655\n",
      "\tLoss: 0.47491154074668884\n",
      "\tLoss: 0.473533034324646\n",
      "\tLoss: 0.47494935989379883\n",
      "\tLoss: 0.475012868642807\n",
      "\tLoss: 0.47275272011756897\n",
      "\tLoss: 0.47512397170066833\n",
      "\tLoss: 0.4731445014476776\n",
      "\tLoss: 0.4726730287075043\n",
      "\tLoss: 0.47607266902923584\n",
      "\tLoss: 0.47254565358161926\n",
      "\tLoss: 0.47138896584510803\n",
      "\n",
      "Skip CurrencyCode.\n",
      "\n",
      "\n",
      "Timezone: epoch 0\n",
      "\tLoss: 0.9637622237205505\n",
      "\tLoss: 0.9734669923782349\n",
      "\tLoss: 0.9676780104637146\n",
      "\tLoss: 0.9688670039176941\n",
      "\tLoss: 0.9640146493911743\n",
      "\tLoss: 0.9694910049438477\n",
      "\tLoss: 0.968641459941864\n",
      "\tLoss: 0.9661823511123657\n",
      "\tLoss: 0.9649375081062317\n",
      "\tLoss: 0.9725332856178284\n",
      "\tLoss: 0.973453938961029\n",
      "\tLoss: 0.9654521346092224\n",
      "\tLoss: 0.9698735475540161\n",
      "\tLoss: 0.9662802219390869\n",
      "\tLoss: 0.9723160266876221\n",
      "\tLoss: 0.9712649583816528\n",
      "\tLoss: 0.9697766304016113\n",
      "\tLoss: 0.9654248952865601\n",
      "\tLoss: 0.9677887558937073\n",
      "\n",
      "Timezone: epoch 1\n",
      "\tLoss: 0.9640800356864929\n",
      "\tLoss: 0.9704816937446594\n",
      "\tLoss: 0.9701191782951355\n",
      "\tLoss: 0.9687694907188416\n",
      "\tLoss: 0.9638798832893372\n",
      "\tLoss: 0.9749205708503723\n",
      "\tLoss: 0.9685863256454468\n",
      "\tLoss: 0.9669433236122131\n",
      "\tLoss: 0.9651026129722595\n",
      "\tLoss: 0.9713665246963501\n",
      "\tLoss: 0.9715813398361206\n",
      "\tLoss: 0.9659330248832703\n",
      "\tLoss: 0.9656043648719788\n",
      "\tLoss: 0.9615333080291748\n",
      "\tLoss: 0.9682590961456299\n",
      "\tLoss: 0.9679040908813477\n",
      "\tLoss: 0.9702408909797668\n",
      "\tLoss: 0.9662092924118042\n",
      "\tLoss: 0.9629083871841431\n",
      "\n",
      "Skip CryptoCurrencyCode.\n",
      "\n",
      "\n",
      "Month: epoch 0\n",
      "\tLoss: 0.7582538723945618\n",
      "\tLoss: 0.7499709129333496\n",
      "\tLoss: 0.7548300623893738\n",
      "\tLoss: 0.751853346824646\n",
      "\tLoss: 0.7551130652427673\n",
      "\tLoss: 0.7524694204330444\n",
      "\tLoss: 0.7538013458251953\n",
      "\tLoss: 0.7616778612136841\n",
      "\tLoss: 0.7570893168449402\n",
      "\tLoss: 0.7509798407554626\n",
      "\tLoss: 0.7511179447174072\n",
      "\tLoss: 0.7541047930717468\n",
      "\tLoss: 0.7542964220046997\n",
      "\tLoss: 0.7534353733062744\n",
      "\tLoss: 0.7512345314025879\n",
      "\tLoss: 0.7519417405128479\n",
      "\tLoss: 0.7525510191917419\n",
      "\tLoss: 0.7560992240905762\n",
      "\tLoss: 0.7558720111846924\n",
      "\n",
      "Month: epoch 1\n",
      "\tLoss: 0.7575743198394775\n",
      "\tLoss: 0.7500299215316772\n",
      "\tLoss: 0.7541229724884033\n",
      "\tLoss: 0.7521999478340149\n",
      "\tLoss: 0.7528268694877625\n",
      "\tLoss: 0.7503815293312073\n",
      "\tLoss: 0.7523611783981323\n",
      "\tLoss: 0.7581958770751953\n",
      "\tLoss: 0.7577196359634399\n",
      "\tLoss: 0.7510116100311279\n",
      "\tLoss: 0.7500230073928833\n",
      "\tLoss: 0.7524056434631348\n",
      "\tLoss: 0.7544751763343811\n",
      "\tLoss: 0.7530156970024109\n",
      "\tLoss: 0.7527297735214233\n",
      "\tLoss: 0.7530781626701355\n",
      "\tLoss: 0.7540599703788757\n",
      "\tLoss: 0.7543378472328186\n",
      "\tLoss: 0.756521463394165\n",
      "\n",
      "Skip Party.\n",
      "\n",
      "\n",
      "B-tim: epoch 0\n",
      "\tLoss: 0.6947120428085327\n",
      "\tLoss: 0.6906814575195312\n",
      "\tLoss: 0.6900293231010437\n",
      "\tLoss: 0.6876430511474609\n",
      "\tLoss: 0.6915215253829956\n",
      "\tLoss: 0.6911041736602783\n",
      "\tLoss: 0.6881900429725647\n",
      "\tLoss: 0.6915532350540161\n",
      "\tLoss: 0.6917316913604736\n",
      "\tLoss: 0.6922042369842529\n",
      "\tLoss: 0.6933013200759888\n",
      "\tLoss: 0.6910776495933533\n",
      "\tLoss: 0.6896855235099792\n",
      "\tLoss: 0.6920719146728516\n",
      "\n",
      "B-tim: epoch 1\n",
      "\tLoss: 0.6948698163032532\n",
      "\tLoss: 0.6893821954727173\n",
      "\tLoss: 0.691908061504364\n",
      "\tLoss: 0.6886836886405945\n",
      "\tLoss: 0.6901435852050781\n",
      "\tLoss: 0.6911646127700806\n",
      "\tLoss: 0.688139021396637\n",
      "\tLoss: 0.6930277347564697\n",
      "\tLoss: 0.6939677596092224\n",
      "\tLoss: 0.6905134320259094\n",
      "\tLoss: 0.6902099847793579\n",
      "\tLoss: 0.6881257891654968\n",
      "\tLoss: 0.6922854781150818\n",
      "\tLoss: 0.6910282969474792\n",
      "\tLoss: 0.6909061074256897\n",
      "\tLoss: 0.6935060620307922\n",
      "\tLoss: 0.6938723921775818\n",
      "\tLoss: 0.6911499500274658\n",
      "\tLoss: 0.691123366355896\n",
      "\n",
      "Skip I-art.\n",
      "\n",
      "\n",
      "Time: epoch 0\n",
      "\tLoss: 0.48999014496803284\n",
      "\tLoss: 0.4838351905345917\n",
      "\tLoss: 0.4911143481731415\n",
      "\tLoss: 0.48915907740592957\n",
      "\tLoss: 0.4887998700141907\n",
      "\tLoss: 0.4884377121925354\n",
      "\tLoss: 0.4891936480998993\n",
      "\tLoss: 0.48787322640419006\n",
      "\tLoss: 0.48921072483062744\n",
      "\tLoss: 0.4904090464115143\n",
      "\tLoss: 0.4893077313899994\n",
      "\tLoss: 0.4885750710964203\n",
      "\tLoss: 0.49067988991737366\n",
      "\tLoss: 0.4871000051498413\n",
      "\tLoss: 0.4901736080646515\n",
      "\tLoss: 0.4912834167480469\n",
      "\tLoss: 0.49236875772476196\n",
      "\tLoss: 0.4881249964237213\n",
      "\tLoss: 0.4888165593147278\n",
      "\n",
      "Time: epoch 1\n",
      "\tLoss: 0.4910660684108734\n",
      "\tLoss: 0.4847155511379242\n"
     ]
    }
   ],
   "source": [
    "for index, tag in enumerate(all_tags):\n",
    "    if index % 2 == train_id:\n",
    "        print(f\"\\nSkip {tag}.\\n\")\n",
    "        continue\n",
    "    model.add_adapter(tag)\n",
    "    model.add_tagging_head(\n",
    "        tag,\n",
    "        num_labels=2\n",
    "      )\n",
    "    model.train_adapter(tag)\n",
    "    model = model.to(device)\n",
    "    for epoch in range(2):\n",
    "        print(f\"\\n{tag}: epoch {epoch}\")\n",
    "        for i, data in enumerate(trainloader):\n",
    "\n",
    "            tokens_tensors, segments_tensors, \\\n",
    "            masks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "            outputs = model(input_ids = tokens_tensors,\n",
    "                attention_mask=masks_tensors,\n",
    "                token_type_ids=segments_tensors)\n",
    "\n",
    "\n",
    "            logits = outputs[0]\n",
    "\n",
    "            current_label = labels.view(-1, labels.shape[-1])[:, trainset.label_map[tag]]\n",
    "            current_label = current_label.view(-1)\n",
    "\n",
    "            active_logits = logits.view(-1, logits.shape[-1])[masks_tensors.view(-1) == 1]\n",
    "            active_labels = current_label[masks_tensors.view(-1)== 1]\n",
    "\n",
    "            active_labels = active_labels.long()\n",
    "\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            loss = loss_fct(active_logits, active_labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if i % 10 == 0:\n",
    "                print(f\"\\tLoss: {loss}\")\n",
    "        telegram_bot_sendtext(f\"\\n{tag}: epoch {epoch}, loss = {loss}\")\n",
    "    model.save_adapter(f\"./save_adapters/{tag}_0730\", model.active_adapters[0])\n",
    "    model.save_head(f\"./save_heads/{tag}_0730\", model.active_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01978eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30771ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e908c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce26589",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.098Z"
    }
   },
   "outputs": [],
   "source": [
    "label_id_mapping = trainset.label_map\n",
    "\n",
    "id_label_mapping = dict()\n",
    "for key in label_id_mapping.keys():\n",
    "    id_label_mapping[label_id_mapping[key]] = key\n",
    "\n",
    "def test_model(model, sentence, device = \"cpu\"):\n",
    "    tokenized_sentence = torch.tensor([tokenizer.encode(sentence)])\n",
    "    pos = torch.tensor([[0] * len(tokenized_sentence)])\n",
    "    tags = torch.tensor([[1] * len(tokenized_sentence)])\n",
    "\n",
    "    model = model.to(device)\n",
    "    outputs = model(input_ids=tokenized_sentence.to(device), \n",
    "                    token_type_ids=pos.to(device), \n",
    "                    attention_mask=tags.to(device))\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    _, pred_labels = torch.max(logits, 2)\n",
    "\n",
    "    out_labels = []\n",
    "    for row in pred_labels:\n",
    "        result = list(map(lambda x: id_label_mapping[int(x)], row))\n",
    "        out_labels.append(result)\n",
    "    #return tokenizer.tokenize(sentence), out_labels[0], logits\n",
    "    return tokenizer.tokenize(sentence), out_labels[0][1:-1], logits[:, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46deba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a87d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656abe32",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.101Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"Dan Will be deemed to have completed its delivery obligations before 2021-7-5 if in Niall's opinion, the Jeep Car satisfies the Acceptance Criteria, and Niall notifies Dan in writing that it is accepting the Jeep Car.\"\n",
    "sen, pred, logits = test_model(model, sentence, device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16220ab",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.102Z"
    }
   },
   "outputs": [],
   "source": [
    "a = tokenizer.tokenize(sentence)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1f6fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d937d0b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.104Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae43e1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.105Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5246a1d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.106Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "def interact_word(i):\n",
    "    print(i)\n",
    "    print(sen[i])\n",
    "    target = out[i]\n",
    "\n",
    "    for i in range(len(target)):\n",
    "        print(f\"{i} {id_label_mapping[i].ljust(6)} \\t: {target[i]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43105772",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.110Z"
    }
   },
   "outputs": [],
   "source": [
    "out = logits[0]\n",
    "interact(lambda x: interact_word(x), x=widgets.IntSlider(min=0, max=len(sen)-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf934d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b2200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea35621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:01:09.267255Z",
     "start_time": "2021-07-30T08:01:09.267245Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdd8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0aa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e508bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfc38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ea919",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-30T08:10:21.118Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e97b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
