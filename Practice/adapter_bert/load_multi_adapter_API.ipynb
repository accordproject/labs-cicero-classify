{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9a0391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:53:59.544137Z",
     "start_time": "2021-08-03T22:53:58.722545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.8.1\n",
      "transformers (Adapter) Version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"transformers (Adapter) Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f380fe09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:09.709203Z",
     "start_time": "2021-08-03T22:53:59.546735Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5d9ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:10.300081Z",
     "start_time": "2021-08-03T22:54:09.711772Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"./NER_multilabel_data_v2.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "all_tags = df.newTag\n",
    "\n",
    "all_tags = set(all_tags)\n",
    "\n",
    "all_tags = \"|\".join(all_tags)\n",
    "all_tags = all_tags.split(\"|\")\n",
    "all_tags = set(all_tags)\n",
    "all_tags = list(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8805000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:17.382769Z",
     "start_time": "2021-08-03T22:54:10.303164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['B-art' 'B-eve' 'B-geo' 'B-gpe' 'B-nat' 'B-org' 'B-per' 'B-tim'\n",
      " 'CountryCode' 'CryptoCurrencyCode' 'CurrencyCode' 'Event' 'Float' 'I-art'\n",
      " 'I-eve' 'I-geo' 'I-gpe' 'I-nat' 'I-org' 'I-per' 'I-tim' 'Integer'\n",
      " 'Location' 'Month' 'O' 'Object' 'Party' 'Race' 'SpecialTerm'\n",
      " 'TemporalUnit' 'Time' 'Timezone' 'US_States']\n"
     ]
    }
   ],
   "source": [
    "from ner_dataset import get_trainset_data_loader\n",
    "\n",
    "all_tags, trainset, trainloader = get_trainset_data_loader(tokenizer, BATCH_SIZE=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557e8a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:21.715848Z",
     "start_time": "2021-08-03T22:54:17.384840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import RobertaConfig, RobertaModelWithHeads\n",
    "\n",
    "config = RobertaConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=len(all_tags),\n",
    "    label2id = trainset.label_map, \n",
    "    id2label = trainset.id2label\n",
    ")\n",
    "model = RobertaModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d6a050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:21.993781Z",
     "start_time": "2021-08-03T22:54:21.718166Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model class 'BertModelWithHeads' of found prediction head does not match current model class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10491/4265241807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./save_adapters/{adapter_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_adapter_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./save_heads/{adapter_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/transformers/adapters/model_mixin.py\u001b[0m in \u001b[0;36mload_head\u001b[0;34m(self, save_directory, load_as)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_as\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictionHeadLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_as\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     def save_adapter(\n",
      "\u001b[0;32m~/data/anaconda3/envs/adapter/lib/python3.7/site-packages/transformers/adapters/loading.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, save_directory, load_as, loading_info)\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_on_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                     raise ValueError(\n\u001b[0;32m--> 638\u001b[0;31m                         \u001b[0;34mf\"Model class '{config['model_class']}' of found prediction head does not match current \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m                         \u001b[0;34mf\"model class.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                     )\n",
      "\u001b[0;31mValueError\u001b[0m: Model class 'BertModelWithHeads' of found prediction head does not match current model class."
     ]
    }
   ],
   "source": [
    "all_adapter_name = []\n",
    "for tag in all_tags:\n",
    "    adapter_name = f\"{tag}_0731\"\n",
    "    name = model.load_adapter(f\"./save_adapters/{adapter_name}\")\n",
    "    all_adapter_name.append(name)\n",
    "    model.load_head(f\"./save_heads/{adapter_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ecefe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:21.995206Z",
     "start_time": "2021-08-03T22:54:21.995195Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190361d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:21.996258Z",
     "start_time": "2021-08-03T22:54:21.996246Z"
    }
   },
   "outputs": [],
   "source": [
    "parallel_text = \"','\".join(all_adapter_name)\n",
    "result = re.findall(r'[;|(|)]',parallel_text)\n",
    "if len(result) != 0:\n",
    "    raise(ValueError(\"Adapter Name must not contain \\\"\" + '\\\", \\\"'.join(result) + '\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688e668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:21.997149Z",
     "start_time": "2021-08-03T22:54:21.997137Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers.adapters.composition import Parallel\n",
    "parallel = eval(\"Parallel('\" + \"','\".join(all_adapter_name) + \"')\")\n",
    "\n",
    "model.set_active_adapters(parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a0c59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:56:50.281042Z",
     "start_time": "2021-07-30T02:56:50.208807Z"
    }
   },
   "source": [
    "adapter_name = \"All_tag_2\"\n",
    "model.load_adapter(f\"./save_adapters/{adapter_name}\")\n",
    "model.load_head(f\"./save_heads/{adapter_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf3993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a935fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434df5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f243f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T22:28:59.759050Z",
     "start_time": "2021-07-31T22:28:59.057721Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6899a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:21.998175Z",
     "start_time": "2021-08-03T22:54:21.998162Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeac768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:21.998819Z",
     "start_time": "2021-08-03T22:54:21.998808Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adapter_mapping(model):\n",
    "    print(model.active_head)\n",
    "    label_2_id_mapping = dict()\n",
    "    id_2_label_mapping = dict()\n",
    "    for i, head in enumerate(model.active_head):\n",
    "        label_2_id_mapping[head] = i\n",
    "        id_2_label_mapping[i] = head\n",
    "    return label_2_id_mapping, id_2_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a965772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad16cb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:21.999785Z",
     "start_time": "2021-08-03T22:54:21.999773Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_predict(model, sentence, device = \"cpu\"):\n",
    "    tokenized_sentence = torch.tensor([tokenizer.encode(sentence)])\n",
    "    pos = torch.tensor([[0] * len(tokenized_sentence)])\n",
    "    tags = torch.tensor([[1] * len(tokenized_sentence)])\n",
    "\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=tokenized_sentence.to(device), \n",
    "                        token_type_ids=pos.to(device), \n",
    "                        attention_mask=tags.to(device))\n",
    "\n",
    "    logits = outputs[1][0]\n",
    "\n",
    "    return_tags_order = {}\n",
    "    all_output = None\n",
    "    for i, output in enumerate(outputs):\n",
    "\n",
    "        return_tags_order[i] = (model.active_head[i])\n",
    "\n",
    "        output = outputs[i][0]\n",
    "\n",
    "        if all_output != None:\n",
    "            all_output = torch.cat((all_output, output), dim=2)\n",
    "        else:\n",
    "            all_output = output\n",
    "    all_output = torch.sigmoid(all_output)\n",
    "\n",
    "    output_array = np.array(all_output)\n",
    "    output_array = output_array.reshape(output_array.shape[-2], output_array.shape[-1])\n",
    "\n",
    "    label_confidences = []\n",
    "    for label_confidence in list(output_array):\n",
    "        label_confidences.append(list(label_confidence))\n",
    "\n",
    "    #Drop Head and End since it is start/stop Token\n",
    "    label_confidences = label_confidences[1:-1]\n",
    "\n",
    "    max_value = np.array(label_confidences).argmax(axis=1)\n",
    "    trans_func = np.vectorize(lambda x: model.active_head[x])\n",
    "    out_labels = trans_func(max_value)\n",
    "\n",
    "    out_sentence = tokenizer.tokenize(sentence)\n",
    "\n",
    "    return out_sentence, out_labels, label_confidences, return_tags_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ac39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:22.000609Z",
     "start_time": "2021-08-03T22:54:22.000598Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"Dan will be deemed to have completed its delivery for 8.2 obligations before 2021-7-5 if in Niall's opinion, the Jeep Car satisfies the Acceptance Criteria, and Niall notifies Dan in writing that it is accepting the Jeep Car.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e0cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:22.001421Z",
     "start_time": "2021-08-03T22:54:22.001410Z"
    }
   },
   "outputs": [],
   "source": [
    "sen, pred, logits, tags_order = model_predict(model, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6a1e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:22.002256Z",
     "start_time": "2021-08-03T22:54:22.002244Z"
    }
   },
   "outputs": [],
   "source": [
    "label_2_id_mapping, id_2_label_mapping = get_adapter_mapping(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef2767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:22.003122Z",
     "start_time": "2021-08-03T22:54:22.003111Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c8084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:22.003869Z",
     "start_time": "2021-08-03T22:54:22.003858Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5458815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd7d01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:22.004710Z",
     "start_time": "2021-08-03T22:54:22.004700Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "def interact_word(i):\n",
    "    print(i)\n",
    "    print(f\"{sen[i].replace('Ä ', '')}: {pred[i]}\")\n",
    "    target = logits[i]\n",
    "\n",
    "    outprint = {}\n",
    "    for i in range(len(target)):\n",
    "        outprint[target[i]] = (f\"{tags_order[i].ljust(6)} \\t: {target[i]:.5f}\")\n",
    "        \n",
    "    outprint_keys = list(outprint.keys())\n",
    "    outprint_keys.sort(reverse=True)\n",
    "    for i, key in enumerate(outprint_keys):\n",
    "        print(f\"{str(i).ljust(2)} {outprint[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4ed4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:54:22.005759Z",
     "start_time": "2021-08-03T22:54:22.005748Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "interact(lambda x: interact_word(x), x=widgets.IntSlider(min=0, max=len(sen)-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe8d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
